{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------------------------------------\n",
    "# Tensorflow Faster R-CNN\n",
    "# Licensed under The MIT License [see LICENSE for details]\n",
    "# Written by Jiasen Lu, Jianwei Yang, based on code from Ross Girshick\n",
    "# --------------------------------------------------------\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "from easydict import EasyDict\n",
    "import _init_paths\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import argparse\n",
    "import pprint\n",
    "import pdb\n",
    "import time\n",
    "import cv2\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import xml.dom.minidom as minidom\n",
    "import PIL\n",
    "from PIL import Image\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "from matplotlib import pyplot as plt\n",
    "try:\n",
    "    import cPickle as pickle\n",
    "    print('import cPickle')\n",
    "except:\n",
    "    import pickle\n",
    "    print('import python pickle')\n",
    "from roi_data_layer.roidb import combined_roidb\n",
    "from roi_data_layer.roibatchLoader import roibatchLoader\n",
    "from model.utils.config import cfg, cfg_from_file, cfg_from_list, get_output_dir\n",
    "from model.rpn.bbox_transform import clip_boxes\n",
    "from model.nms.nms_wrapper import nms\n",
    "from model.rpn.bbox_transform import bbox_transform_inv\n",
    "from model.utils.net_utils import save_net, load_net, vis_detections\n",
    "from model.faster_rcnn.vgg16 import vgg16\n",
    "from model.faster_rcnn.resnet import resnet\n",
    "#from model.faster_rcnn.faster_rcnn import _fasterRCNN\n",
    "from model.siamese_net.siameseRCNN import _siameseRCNN\n",
    "from model.siamese_net.weight_cropping_layer import weight_crop_layer\n",
    "\n",
    "import pdb\n",
    "\n",
    "try:\n",
    "    xrange          # Python 2\n",
    "except NameError:\n",
    "    xrange = range  # Python 3\n",
    "\n",
    "torch.cuda.set_device(0)\n",
    "def parse_args():\n",
    "    \"\"\"\n",
    "    Parse input arguments\n",
    "    \"\"\"\n",
    "    args = EasyDict()\n",
    "    args['dataset'] = 'imagenetVID_PLUS'\n",
    "    args['net'] = 'res101'\n",
    "    args['load_dir'] = 'models'\n",
    "    args['cuda'] = True\n",
    "    args['vid_size'] = 1\n",
    "    args['class_agnostic'] = False\n",
    "    args['cfg_file'] = 'cfgs/res101_lighthead_siam.yml'\n",
    "    args['ckpt'] = '1_8_54269'\n",
    "    return args\n",
    "\n",
    "def bbox_delta_to_pred_boxes(im_info, boxes, bbox_pred):\n",
    "    box_deltas = bbox_pred.data\n",
    "    if cfg.TRAIN.BBOX_NORMALIZE_TARGETS_PRECOMPUTED:\n",
    "        # Optionally normalize targets by a precomputed mean and stdev\n",
    "        if args.class_agnostic:\n",
    "            box_deltas = box_deltas.view(-1, 4) * torch.FloatTensor(cfg.TRAIN.BBOX_NORMALIZE_STDS).cuda() \\\n",
    "                         + torch.FloatTensor(cfg.TRAIN.BBOX_NORMALIZE_MEANS).cuda()\n",
    "            box_deltas = box_deltas.view(1, -1, 4)\n",
    "        else:\n",
    "            box_deltas = box_deltas.view(-1, 4) * torch.FloatTensor(cfg.TRAIN.BBOX_NORMALIZE_STDS).cuda() \\\n",
    "                         + torch.FloatTensor(cfg.TRAIN.BBOX_NORMALIZE_MEANS).cuda()\n",
    "            box_deltas = box_deltas.view(1, -1, 4 * len(imdb.classes))\n",
    "\n",
    "    pred_boxes = bbox_transform_inv(boxes, box_deltas, 1)\n",
    "    pred_boxes = clip_boxes(pred_boxes, im_info.data, 1)\n",
    "    return pred_boxes\n",
    "\n",
    "weight_cropper = weight_crop_layer().cuda()\n",
    "def siam_weights_preparation(rois_tracking, base_feat):\n",
    "    if rois_tracking is None:\n",
    "        return None, None\n",
    "    else:\n",
    "        rois_tracking = Variable(base_feat.new_tensor(rois_tracking))\n",
    "        boxes = rois_tracking[:,:4]\n",
    "        batch_inds = boxes.new_zeros((boxes.size(0),1))\n",
    "        boxes = torch.cat((batch_inds, boxes),dim=1)\n",
    "        template_weights = weight_cropper(base_feat, boxes)\n",
    "        return template_weights, rois_tracking\n",
    "\n",
    "def prepare_rois_tracking(im_info, all_boxes, all_boxes_scores, frame_id, class_num, thresh=cfg.SIAMESE.THRESH_FOR_TRACKING):\n",
    "    # class_num is 31 for imagenetVID.\n",
    "    sel_boxes = []\n",
    "    for j in range(1, class_num):\n",
    "        if len(all_boxes[j][frame_id]) == 0:\n",
    "            continue\n",
    "        scored_boxes = all_boxes[j][frame_id].copy()\n",
    "        scores = all_boxes_scores[j][frame_id].copy()\n",
    "        assert len(scored_boxes)==len(scores), 'length of scored_boxes and length of scores should be the equal.'\n",
    "        # TODO comment out the following for loop to accelerate predictions.\n",
    "        scored_boxes[:, :4] = scored_boxes[:, :4] * im_info[-1]\n",
    "        for b_id in range(len(scored_boxes)):\n",
    "            assert scored_boxes[b_id, 4] == scores[b_id, j], 'scores not matched, please check your code.%f!=%f'%(scored_boxes[b_id, 4],scores[b_id, j])\n",
    "        inds = np.where(scored_boxes[:, 4]>thresh)[0]\n",
    "        if len(inds)>0:\n",
    "            sel_cls_boxes = np.concatenate((scored_boxes[inds,:4], scores[inds,:]), axis=1)\n",
    "            sel_boxes.append(sel_cls_boxes)\n",
    "        else:\n",
    "            continue\n",
    "    if len(sel_boxes)>0:\n",
    "        rois_tracking = np.concatenate(sel_boxes, axis=0)\n",
    "    else:\n",
    "        rois_tracking = None\n",
    "    return rois_tracking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = parse_args()\n",
    "\n",
    "print('Called with args:')\n",
    "print(args)\n",
    "\n",
    "if torch.cuda.is_available() and not args.cuda:\n",
    "    print(\"WARNING: You have a CUDA device, so you should probably run with --cuda\")\n",
    "\n",
    "np.random.seed(cfg.RNG_SEED)\n",
    "if args.dataset == \"imagenetVID\":\n",
    "    args.imdb_name = 'imagenetVID_train'\n",
    "    args.imdbval_name = 'imagenetVID_val'\n",
    "    args.set_cfgs = ['ANCHOR_SCALES', '[4, 8, 16, 32]', 'ANCHOR_RATIOS', '[0.5,1,2]', 'MAX_NUM_GT_BOXES', '30']\n",
    "elif args.dataset == \"imagenetVID_PLUS\":\n",
    "    args.imdb_name = 'imagenetVID_PLUS_train'\n",
    "    args.imdbval_name = 'imagenetVID_PLUS_val'\n",
    "    args.set_cfgs = ['ANCHOR_SCALES', '[4, 8, 16, 32]', 'ANCHOR_RATIOS', '[0.5,1,2]', 'MAX_NUM_GT_BOXES', '30']\n",
    "elif args.dataset == \"imagenetVID_1_vid\":\n",
    "    args.imdb_name = 'imagenetVID_1_vid_train'\n",
    "    # TODO imdbval is set to train set now.\n",
    "    args.imdbval_name = 'imagenetVID_1_vid_train'\n",
    "    args.set_cfgs = ['ANCHOR_SCALES', '[4, 8, 16, 32]', 'ANCHOR_RATIOS', '[0.5,1,2]', 'MAX_NUM_GT_BOXES', '30']\n",
    "\n",
    "if args.cfg_file is None:\n",
    "    args.cfg_file = \"cfgs/{}_ls.yml\".format(args.net) if args.large_scale else \"cfgs/{}.yml\".format(args.net)\n",
    "\n",
    "if args.cfg_file is not None:\n",
    "    cfg_from_file(args.cfg_file)\n",
    "if args.set_cfgs is not None:\n",
    "    cfg_from_list(args.set_cfgs)\n",
    "\n",
    "print('Using config:')\n",
    "pprint.pprint(cfg)\n",
    "\n",
    "cfg.TRAIN.USE_FLIPPED = False\n",
    "imdb, roidb, ratio_list, ratio_index = combined_roidb(args.imdbval_name, False)\n",
    "imdb.competition_mode(on=True)\n",
    "\n",
    "print('{:d} roidb entries'.format(len(roidb)))\n",
    "\n",
    "input_dir = args.load_dir + \"/\" + args.net + \"/\" + args.dataset\n",
    "if not os.path.exists(input_dir):\n",
    "    raise Exception('There is no input directory for loading network from ' + input_dir)\n",
    "\n",
    "#print('cfg.RESNET.CORE_CHOICE.USE:',cfg.RESNET.CORE_CHOICE.USE)\n",
    "load_name_predix = cfg.RESNET.CORE_CHOICE.USE + '_siam'\n",
    "if cfg.TRAIN.OHEM is True:\n",
    "    load_name_predix = load_name_predix+'_OHEM'\n",
    "load_name = os.path.join(input_dir, load_name_predix+'_{}.pth'.format(args.ckpt))\n",
    "\n",
    "# initilize the network here.\n",
    "if args.net == 'res101':\n",
    "    RCNN = _siameseRCNN(imdb.classes, args)\n",
    "else:\n",
    "    print(\"network is not defined\")\n",
    "    pdb.set_trace()\n",
    "\n",
    "print(\"load checkpoint %s\" % (load_name))\n",
    "checkpoint = torch.load(load_name)\n",
    "RCNN.load_state_dict(checkpoint['model'])\n",
    "if 'pooling_mode' in checkpoint.keys():\n",
    "    cfg.POOLING_MODE = checkpoint['pooling_mode']\n",
    "\n",
    "\n",
    "print('load model successfully!')\n",
    "# initilize the tensor holder here.\n",
    "im_data = torch.FloatTensor(1)\n",
    "im_info = torch.FloatTensor(1)\n",
    "num_boxes = torch.LongTensor(1)\n",
    "gt_boxes = torch.FloatTensor(1)\n",
    "\n",
    "# ship to cuda\n",
    "if args.cuda:\n",
    "    im_data = im_data.cuda()\n",
    "    im_info = im_info.cuda()\n",
    "    num_boxes = num_boxes.cuda()\n",
    "    gt_boxes = gt_boxes.cuda()\n",
    "\n",
    "# make variable\n",
    "im_data = Variable(im_data)\n",
    "im_info = Variable(im_info)\n",
    "num_boxes = Variable(num_boxes)\n",
    "gt_boxes = Variable(gt_boxes)\n",
    "\n",
    "if args.cuda:\n",
    "    cfg.CUDA = True\n",
    "\n",
    "if args.cuda:\n",
    "    RCNN.cuda()\n",
    "\n",
    "start = time.time()\n",
    "max_per_image = 100\n",
    "\n",
    "thresh = 0.01\n",
    "\n",
    "#save_name = 'light_head_rcnn_10'\n",
    "save_name = load_name_predix\n",
    "num_images = len(imdb.image_index)\n",
    "\n",
    "output_dir = get_output_dir(imdb, save_name)\n",
    "dataset = roibatchLoader(roidb, ratio_list, ratio_index, 1, \\\n",
    "                    imdb.num_classes, training=False, normalize = False)\n",
    "#dataloader = torch.utils.data.DataLoader(dataset, batch_size=1,\n",
    "#                        shuffle=False, num_workers=0,\n",
    "#                        pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io as sio\n",
    "devkit_path = 'data/imagenet/ILSVRC/devkit'\n",
    "####VID object info####\n",
    "synsets_video = sio.loadmat(os.path.join(devkit_path,'data','meta_vid.mat'))\n",
    "_wnid = (0,)\n",
    "_classes = ('__background__',)\n",
    "for i in xrange(30):\n",
    "    _classes = _classes + (synsets_video['synsets'][0][i][2][0],)\n",
    "    _wnid = _wnid + (synsets_video['synsets'][0][i][1][0],)\n",
    "\n",
    "_wnid_to_ind = dict(zip(_wnid, xrange(31)))\n",
    "_class_to_ind = dict(zip(_classes, xrange(31)))\n",
    "#######################\n",
    "def read_annotation(dataPath):\n",
    "    filename = dataPath.replace('Data','Annotations').replace('JPEG','xml')\n",
    "    assert os.path.exists(filename),'%s'%(filename)\n",
    "    # print 'Loading: {}'.format(filename)\n",
    "    def get_data_from_tag(node, tag):\n",
    "        return node.getElementsByTagName(tag)[0].childNodes[0].data\n",
    "\n",
    "    with open(filename) as f:\n",
    "        data = minidom.parseString(f.read())\n",
    "\n",
    "    objs = data.getElementsByTagName('object')\n",
    "    num_objs = len(objs)\n",
    "    \n",
    "    boxes = np.zeros((num_objs, 4), dtype=np.int32)\n",
    "    gt_classes = np.zeros(num_objs,dtype=np.int32)\n",
    "    # Load object bounding boxes into a data frame.\n",
    "    for ix, obj in enumerate(objs):\n",
    "        x1 = float(get_data_from_tag(obj, 'xmin'))\n",
    "        y1 = float(get_data_from_tag(obj, 'ymin'))\n",
    "        x2 = float(get_data_from_tag(obj, 'xmax'))\n",
    "        y2 = float(get_data_from_tag(obj, 'ymax'))\n",
    "        cls = _wnid_to_ind[\n",
    "                str(get_data_from_tag(obj, \"name\")).lower().strip()]\n",
    "        boxes[ix, :] = [x1, y1, x2, y2]\n",
    "        gt_classes[ix] = cls\n",
    "    return boxes, gt_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def showBoxResult(img_id, all_boxes, imdb, show_class=True, threshold=0.3, dpi = 200,all_boxes_tracking=None,all_boxes_detection=None):\n",
    "    imIdx = imdb.image_index[img_id]+'.JPEG'\n",
    "    assert os.path.exists(imIdx), imIdx+' does not exist.'\n",
    "    #print(imIdx)\n",
    "    gt_boxes, gt_classes = read_annotation(imIdx)\n",
    "    im2show = np.array(PIL.Image.open(imIdx))\n",
    "    fig = plt.figure(frameon=False)\n",
    "    fig.set_size_inches(im2show.shape[1] / dpi, im2show.shape[0] / dpi)\n",
    "    ax = plt.Axes(fig, [0., 0., 1., 1.])\n",
    "    ax.axis('off')\n",
    "    fig.add_axes(ax)\n",
    "    ax.imshow(im2show)\n",
    "    \n",
    "    #draw gt first\n",
    "    for j in range(len(gt_classes)):\n",
    "        ax.add_patch(\n",
    "        plt.Rectangle((gt_boxes[j][0], gt_boxes[j][1]),\n",
    "                      gt_boxes[j][2] - gt_boxes[j][0],\n",
    "                      gt_boxes[j][3] - gt_boxes[j][1],\n",
    "                      fill=False, edgecolor='g',\n",
    "                      linewidth=2.0, alpha=0.8))\n",
    "        if show_class:\n",
    "            ax.text(gt_boxes[j][0], gt_boxes[j][1] - 2,\n",
    "            '%s %f'%(imdb.classes[gt_classes[j]], 1.0),\n",
    "            fontsize=10,\n",
    "            #family='serif',\n",
    "            bbox=dict(facecolor='g', alpha=0.5, pad=0, edgecolor='none'),\n",
    "                color='white')\n",
    " \n",
    "    #draw dets\n",
    "    for j in range(len(imdb.classes)):\n",
    "        if isinstance(all_boxes[j][img_id], np.ndarray):\n",
    "            for bbox in all_boxes[j][img_id]:\n",
    "                if bbox[-1]>threshold:\n",
    "                    ax.add_patch(\n",
    "                    plt.Rectangle((bbox[0], bbox[1]),\n",
    "                              bbox[2] - bbox[0],\n",
    "                              bbox[3] - bbox[1],\n",
    "                              fill=False, edgecolor='y',\n",
    "                              linewidth=2.0, alpha=0.4))\n",
    "                    if show_class:\n",
    "                        ax.text(bbox[0], bbox[1] - 2,\n",
    "                        '%s %f'%(imdb.classes[j], bbox[-1]),\n",
    "                        fontsize=10,\n",
    "                        #family='serif',\n",
    "                        bbox=dict(\n",
    "                            facecolor='y', alpha=0.5, pad=0, edgecolor='none'),\n",
    "                            color='white')\n",
    "            #im2show = vis_detections(im2show, imdb.classes[j], all_boxes[j][img_id], 0.3)\n",
    "    #plt.show()\n",
    "    if all_boxes_detection is not None:\n",
    "        for j in range(len(imdb.classes)):\n",
    "            if isinstance(all_boxes_detection[j][img_id], np.ndarray):\n",
    "                for bbox in all_boxes_detection[j][img_id]:\n",
    "                    if bbox[-1]>threshold:\n",
    "                        ax.add_patch(\n",
    "                        plt.Rectangle((bbox[0], bbox[1]),\n",
    "                                  bbox[2] - bbox[0],\n",
    "                                  bbox[3] - bbox[1],\n",
    "                                  fill=False, edgecolor='m',\n",
    "                                  linewidth=2.0, alpha=0.2))\n",
    "                        if show_class:\n",
    "                            ax.text(bbox[0], bbox[1] - 2,\n",
    "                            '%s %f'%(imdb.classes[j], bbox[-1]),\n",
    "                            fontsize=10,\n",
    "                            #family='serif',\n",
    "                            bbox=dict(\n",
    "                                facecolor='m', alpha=0.2, pad=0, edgecolor='none'),\n",
    "                                color='white')\n",
    "    \n",
    "    if all_boxes_tracking is not None:\n",
    "        for j in range(len(imdb.classes)):\n",
    "            if isinstance(all_boxes_tracking[j][img_id], np.ndarray):\n",
    "                for bbox in all_boxes_tracking[j][img_id]:\n",
    "                    if bbox[-1]>threshold:\n",
    "                        ax.add_patch(\n",
    "                        plt.Rectangle((bbox[0], bbox[1]),\n",
    "                                  bbox[2] - bbox[0],\n",
    "                                  bbox[3] - bbox[1],\n",
    "                                  fill=False, edgecolor='w',\n",
    "                                  linewidth=2.0, alpha=0.4))\n",
    "                        if show_class:\n",
    "                            ax.text(bbox[0], bbox[1] - 2,\n",
    "                            '%s %f'%(imdb.classes[j], bbox[-1]),\n",
    "                            fontsize=10,\n",
    "                            #family='serif',\n",
    "                            bbox=dict(\n",
    "                                facecolor='w', alpha=0.5, pad=0, edgecolor='none'),\n",
    "                                color='white')\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def makeVid(imdb,all_boxes,img_ids,vid_id,dname_prefix='output/tmp_vid',dir_suffix='',ext='png',all_boxes_tracking=None,all_boxes_detection=None):\n",
    "    name_ls = []\n",
    "    dname = dname_prefix+'_%03d'%(vid_id)+dir_suffix\n",
    "    if not os.path.exists(dname):\n",
    "        os.mkdir(dname)\n",
    "        assert os.path.exists(dname)\n",
    "    for i in img_ids:\n",
    "        fname = os.path.join(dname,'%08d'%(i)+'.'+ext)\n",
    "        fig = showBoxResult(i,all_boxes,imdb,all_boxes_tracking=all_boxes_tracking,all_boxes_detection=all_boxes_detection)\n",
    "        fig.savefig(fname)\n",
    "        plt.close(fig)\n",
    "        name_ls.append(fname)\n",
    "    return name_ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_boxes = [[[] for _ in xrange(num_images)]\n",
    "           for _ in xrange(imdb.num_classes)]\n",
    "all_boxes_scores = [[[] for _ in xrange(num_images)]\n",
    "                   for _ in xrange(imdb.num_classes)]\n",
    "SEE_TRACKING=True\n",
    "SEE_DETECTION=True\n",
    "if SEE_TRACKING:\n",
    "    all_boxes_tracking = [[[] for _ in xrange(num_images)]\n",
    "               for _ in xrange(imdb.num_classes)]\n",
    "if SEE_DETECTION:\n",
    "    all_boxes_detection = [[[] for _ in xrange(num_images)]\n",
    "               for _ in xrange(imdb.num_classes)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PyPDF2 import PdfFileMerger\n",
    "def SEE_VIDS(vids_id_list, MODE=0):\n",
    "    # MODE: 0 det+tra; 1 det; 2 tra\n",
    "    for SEE_VID_ID in vids_id_list:\n",
    "        #data_iter = iter(dataloader)\n",
    "\n",
    "        _t = {'im_detect': time.time(), 'misc': time.time()}\n",
    "        det_file = os.path.join(output_dir, 'detections.pkl')\n",
    "\n",
    "        RCNN.eval()\n",
    "        empty_array = np.transpose(np.array([[],[],[],[],[]]), (1,0))\n",
    "\n",
    "        template_weights = None\n",
    "        rois_tracking = None\n",
    "\n",
    "\n",
    "        #for i in range(num_images):\n",
    "        for i in range(imdb._structured_indexes[SEE_VID_ID][0],imdb._structured_indexes[SEE_VID_ID][-1]+1):\n",
    "            data = dataset.__getitem__(i)\n",
    "            sys.stdout.write('Processing vid %d: %d/%d. \\r' % (SEE_VID_ID, i-imdb._structured_indexes[SEE_VID_ID][0]+1,\n",
    "                                                 len(imdb._structured_indexes[SEE_VID_ID])))\n",
    "            sys.stdout.flush()\n",
    "            data = list(data)\n",
    "            data[0] = data[0].unsqueeze(0)\n",
    "            data[1] = data[1].unsqueeze(0)\n",
    "            data = tuple(data)\n",
    "            #data[2] = data[2].unsqueeze(0)\n",
    "            im_data.data.resize_(data[0].size()).copy_(data[0])\n",
    "            im_info.data.resize_(data[1].size()).copy_(data[1])\n",
    "            #gt_boxes.data.resize_(data[2].size()).copy_(data[2])\n",
    "            #num_boxes.data.resize_(data[3].size()).copy_(data[3])\n",
    "\n",
    "            input = im_data, im_info, template_weights, rois_tracking\n",
    "\n",
    "            det_tic = time.time()\n",
    "            siam_rois, siam_bbox_pred, siam_cls_prob, rois, rois_label, cls_prob, bbox_pred = RCNN(input)\n",
    "\n",
    "            scores = None\n",
    "            pred_boxes = None\n",
    "            ###########################################\n",
    "            # Get detection boxes.\n",
    "            ###########################################\n",
    "            if cfg.TEST.BBOX_REG:\n",
    "                if rois is not None:\n",
    "                    boxes = rois.data[:, :, 1:5]\n",
    "                    pred_boxes = bbox_delta_to_pred_boxes(im_info, boxes, bbox_pred)\n",
    "\n",
    "                    pred_rois = pred_boxes[:,4:].view(-1,4)\n",
    "                    pred_rois = torch.cat((pred_boxes.new_zeros(pred_rois.size(0),1),pred_rois),dim=1).unsqueeze(0)\n",
    "                    bbox_pred, cls_prob, cls_score = RCNN.RCNN.base_feat_to_roi_pred(RCNN.RCNN.base_feat_for_roi, pred_rois, None)\n",
    "                    boxes = pred_rois.data[:, :, 1:5]\n",
    "                    pred_boxes = bbox_delta_to_pred_boxes(im_info, boxes, bbox_pred)\n",
    "                    scores = cls_prob.data\n",
    "\n",
    "                    pred_boxes /= data[1][0][2].item()\n",
    "                    scores = scores.squeeze()\n",
    "                    pred_boxes = pred_boxes.squeeze()\n",
    "                    ###TODO###\n",
    "                    # For debug only.\n",
    "                    if SEE_DETECTION:\n",
    "                        for j in xrange(1, imdb.num_classes):\n",
    "                            inds = torch.nonzero(scores[:,j]>0).view(-1)\n",
    "                            # if there is det\n",
    "                            if inds.numel() > 0:\n",
    "                                cls_scores = scores[:,j][inds]\n",
    "                                _, order = torch.sort(cls_scores, 0, True)\n",
    "                                if args.class_agnostic:\n",
    "                                    cls_boxes = pred_boxes[inds, :]\n",
    "                                else:\n",
    "                                    cls_boxes = pred_boxes[inds][:, j * 4:(j + 1) * 4]\n",
    "                                cls_dets = torch.cat((cls_boxes, cls_scores.unsqueeze(1)), 1)\n",
    "                                #cls_dets = torch.cat((cls_boxes, cls_scores), 1)\n",
    "                                cls_dets = cls_dets[order]\n",
    "                                ######### nms for each cls here ########\n",
    "                                keep = nms(cls_dets, cfg.TEST.NMS)\n",
    "                                cls_dets = cls_dets[keep.view(-1).long()]\n",
    "                                all_boxes_detection[j][i] = cls_dets.cpu().numpy()\n",
    "                            else:\n",
    "                                all_boxes_detection[j][i] = empty_array\n",
    "                    \n",
    "                if siam_bbox_pred is not None:\n",
    "                    siam_scores = siam_cls_prob.data\n",
    "                    siam_boxes = siam_rois.data[:, 1:5]\n",
    "                    pred_siam_bbox = bbox_delta_to_pred_boxes(im_info, siam_boxes.unsqueeze(0), siam_bbox_pred.unsqueeze(0))                                                            \n",
    "                    pred_siam_bbox /= data[1][0][2].item()\n",
    "                    pred_siam_bbox = pred_siam_bbox.squeeze(0)\n",
    "                    # concatenate siambox and detbox.\n",
    "                    if MODE==0:\n",
    "                        if rois is not None:\n",
    "                            pred_boxes = torch.cat((pred_boxes, pred_siam_bbox), 0)\n",
    "                            scores = torch.cat((scores, siam_scores), 0)\n",
    "                        else:\n",
    "                            pred_boxes = pred_siam_bbox\n",
    "                            scores = siam_scores\n",
    "                    #####################\n",
    "                    if MODE==2:\n",
    "                        #####################\n",
    "                        #pred_boxes = pred_siam_bbox\n",
    "                        #####################\n",
    "                        pred_boxes = siam_boxes.repeat(1,siam_boxes.size(1)*31)\n",
    "                        pred_boxes = pred_boxes/im_info[0][-1]\n",
    "                        scores = siam_scores\n",
    "                    ###TODO###\n",
    "                    # For debug only.\n",
    "                    if SEE_TRACKING:\n",
    "                        for j in xrange(1, imdb.num_classes):\n",
    "                            inds = torch.nonzero(siam_scores[:,j]>0).view(-1)\n",
    "                            # if there is det\n",
    "                            if inds.numel() > 0:\n",
    "                                cls_scores = siam_scores[:,j][inds]\n",
    "                                #_, order = torch.sort(cls_scores, 0, True)\n",
    "                                if args.class_agnostic:\n",
    "                                    cls_boxes = pred_siam_bbox[inds, :]\n",
    "                                else:\n",
    "                                    cls_boxes = pred_siam_bbox[inds][:, j * 4:(j + 1) * 4]\n",
    "                                cls_dets = torch.cat((cls_boxes, cls_scores.unsqueeze(1)), 1)\n",
    "                                # cls_dets = torch.cat((cls_boxes, cls_scores), 1)\n",
    "                                #cls_dets = cls_dets[order]\n",
    "                                ######### nms for each cls here ########\n",
    "                                #keep = nms(cls_dets, cfg.TEST.NMS)\n",
    "                                #cls_dets = cls_dets[keep.view(-1).long()]\n",
    "                                all_boxes_tracking[j][i] = cls_dets.cpu().numpy()\n",
    "                            else:\n",
    "                                all_boxes_tracking[j][i] = empty_array\n",
    "            else:\n",
    "                raise ValueError('Error. Should set cfg.TEST.BBOX_REG to True.')\n",
    "\n",
    "            det_toc = time.time()\n",
    "            detect_time = det_toc - det_tic\n",
    "            misc_tic = time.time()\n",
    "            ###########################################\n",
    "            # NMS for detection and save to all boxes.\n",
    "            ###########################################\n",
    "            if scores is not None:\n",
    "                for j in xrange(1, imdb.num_classes):\n",
    "                    inds = torch.nonzero(scores[:,j]>thresh).view(-1)\n",
    "                    # if there is det\n",
    "                    if inds.numel() > 0:\n",
    "                        cls_scores = scores[:,j][inds]\n",
    "                        all_scores = scores[inds]\n",
    "                        _, order = torch.sort(cls_scores, 0, True)\n",
    "                        if args.class_agnostic:\n",
    "                            cls_boxes = pred_boxes[inds, :]\n",
    "                        else:\n",
    "                            cls_boxes = pred_boxes[inds][:, j * 4:(j + 1) * 4]\n",
    "                        cls_dets = torch.cat((cls_boxes, cls_scores.unsqueeze(1)), 1)\n",
    "                        # cls_dets = torch.cat((cls_boxes, cls_scores), 1)\n",
    "                        cls_dets = cls_dets[order]\n",
    "                        all_scores = all_scores[order]\n",
    "                        ######### nms for each cls here ########\n",
    "                        keep = nms(cls_dets, cfg.TEST.NMS)\n",
    "                        cls_dets = cls_dets[keep.view(-1).long()]\n",
    "                        all_cls_scores = all_scores[keep.view(-1).long()]\n",
    "                        all_boxes[j][i] = cls_dets.cpu().numpy()\n",
    "                        all_boxes_scores[j][i] = all_cls_scores.cpu().numpy()\n",
    "                    else:\n",
    "                        all_boxes[j][i] = empty_array\n",
    "                        all_boxes_scores[j][i] = empty_array\n",
    "            else:\n",
    "                for j in xrange(1, imdb.num_classes):\n",
    "                    all_boxes[j][i] = empty_array\n",
    "                    all_boxes_scores[j][i] = empty_array\n",
    "\n",
    "            # Limit to max_per_image detections *over all classes*\n",
    "            if max_per_image > 0:\n",
    "                image_scores = np.hstack([all_boxes[j][i][:, -1]\n",
    "                                        for j in xrange(1, imdb.num_classes)])\n",
    "                if len(image_scores) > max_per_image:\n",
    "                    image_thresh = np.sort(image_scores)[-max_per_image]\n",
    "                    for j in xrange(1, imdb.num_classes):\n",
    "                        keep = np.where(all_boxes[j][i][:, -1] >= image_thresh)[0]\n",
    "                        all_boxes[j][i] = all_boxes[j][i][keep, :]\n",
    "                        all_boxes_scores[j][i] = all_boxes_scores[j][i][keep, :]\n",
    "\n",
    "            # nms between classes.\n",
    "            if cfg.TEST.NMS_CROSS_CLASS > 0.:\n",
    "                cls_boxes = [[]]+[all_boxes[j][i] for j in range(1, imdb.num_classes)]\n",
    "                cls_boxes_scores = [[]]+[all_boxes_scores[j][i] for j in range(1, imdb.num_classes)]\n",
    "                cls_box_list = [cls_boxes[j] for j in range(1, imdb.num_classes) if len(cls_boxes[j])>0]\n",
    "                if len(cls_box_list)>0:\n",
    "                    all_dets = np.vstack(cls_box_list)\n",
    "                    all_dets_scores = np.vstack([cls_boxes_scores[j] for j in range(1, imdb.num_classes) if len(cls_boxes[j])>0])\n",
    "                    class_ids = np.vstack(\n",
    "                        [np.ones(shape=(len(cls_boxes[j]), 1))*j for j in range(1, imdb.num_classes) if len(cls_boxes[j])>0])\n",
    "                    _inds = np.argsort(-all_dets[:,-1])\n",
    "                    all_dets = all_dets[_inds,:]\n",
    "                    all_dets_scores = all_dets_scores[_inds,:]\n",
    "                    class_ids = class_ids[_inds,:]\n",
    "\n",
    "                    keep = nms(torch.tensor(all_dets.astype(np.float32)).cuda(), cfg.TEST.NMS_CROSS_CLASS).view(-1).long().cpu().numpy()\n",
    "                    all_dets = all_dets[keep, :]\n",
    "                    all_dets_scores = all_dets_scores[keep, :]\n",
    "                    class_ids = class_ids[keep, :]\n",
    "                    for j in range(1, imdb.num_classes):\n",
    "                        idx_j = np.where(class_ids==j)[0]\n",
    "                        all_boxes[j][i] = all_dets[idx_j, :]\n",
    "                        all_boxes_scores[j][i] = all_dets_scores[idx_j, :]\n",
    "\n",
    "            ########\n",
    "            # Get weights for the next iteration.\n",
    "            ########\n",
    "            # First, convert all_boxes to rois_tracking.#\n",
    "            # TODO change threshold.\n",
    "            rois_tracking = prepare_rois_tracking(im_info[0], all_boxes, all_boxes_scores, frame_id=i,\n",
    "                                                class_num=imdb.num_classes, thresh=0.9)\n",
    "            base_feat = RCNN.track_feat_trans_1.cuda()(RCNN.RCNN.Conv_feat_track)\n",
    "            template_weights, rois_tracking = siam_weights_preparation(rois_tracking, base_feat)\n",
    "\n",
    "            misc_toc = time.time()\n",
    "            nms_time = misc_toc - misc_tic\n",
    "            \n",
    "            '''\n",
    "            sys.stdout.write('im_detect: {:d}/{:d} {:.3f}s {:.3f}s   \\r' \\\n",
    "              .format(i + 1, num_images, detect_time, nms_time))\n",
    "            sys.stdout.flush()\n",
    "            '''\n",
    "\n",
    "        #with open(det_file, 'wb') as f:\n",
    "            #pickle.dump(all_boxes, f, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "        #print('Evaluating detections')\n",
    "        #imdb.evaluate_detections(all_boxes, output_dir)\n",
    "\n",
    "        end = time.time()\n",
    "        print('')\n",
    "        print(\"test time: %0.4fs\" % (end - start))\n",
    "        \n",
    "        img_ids = imdb._structured_indexes[SEE_VID_ID]\n",
    "        dir_suffix = ''\n",
    "        if MODE==1:\n",
    "            dir_suffix='_det'\n",
    "        elif MODE==2:\n",
    "            dir_suffix='_tra'\n",
    "        name_ls = makeVid(imdb,all_boxes,img_ids,SEE_VID_ID,\n",
    "                          dname_prefix='output/tmp_vid',\n",
    "                          dir_suffix=dir_suffix,ext='pdf',\n",
    "                          all_boxes_tracking=all_boxes_tracking,\n",
    "                          all_boxes_detection=all_boxes_detection)\n",
    "        \n",
    "        pdfs = name_ls\n",
    "        merger = PdfFileMerger()\n",
    "\n",
    "        for pdf in pdfs:\n",
    "            merger.append(open(pdf, 'rb'))\n",
    "\n",
    "        with open(os.path.join(os.path.dirname(pdfs[0]),'result.pdf'), 'wb') as fout:\n",
    "            merger.write(fout)\n",
    "            \n",
    "        print(os.path.join(os.path.dirname(pdfs[0]),'result.pdf'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VIDS_IDS = list(range(101,300))\n",
    "SEE_VIDS(VIDS_IDS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Below are more detailed control."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0 det+tra; 1 det; 2 tra\n",
    "MODE = 0\n",
    "SEE_TRACKING=True\n",
    "SEE_DETECTION=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_boxes = [[[] for _ in xrange(num_images)]\n",
    "           for _ in xrange(imdb.num_classes)]\n",
    "all_boxes_scores = [[[] for _ in xrange(num_images)]\n",
    "                   for _ in xrange(imdb.num_classes)]\n",
    "if SEE_TRACKING:\n",
    "    all_boxes_tracking = [[[] for _ in xrange(num_images)]\n",
    "               for _ in xrange(imdb.num_classes)]\n",
    "if SEE_DETECTION:\n",
    "    all_boxes_detection = [[[] for _ in xrange(num_images)]\n",
    "               for _ in xrange(imdb.num_classes)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEE_VID_ID = 23"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_iter = iter(dataloader)\n",
    "\n",
    "_t = {'im_detect': time.time(), 'misc': time.time()}\n",
    "det_file = os.path.join(output_dir, 'detections.pkl')\n",
    "\n",
    "RCNN.eval()\n",
    "empty_array = np.transpose(np.array([[],[],[],[],[]]), (1,0))\n",
    "\n",
    "template_weights = None\n",
    "rois_tracking = None\n",
    "\n",
    "\n",
    "#for i in range(num_images):\n",
    "for i in range(imdb._structured_indexes[SEE_VID_ID][0],imdb._structured_indexes[SEE_VID_ID][-1]+1):\n",
    "    data = dataset.__getitem__(i)\n",
    "    print('Processing vid %d: %d/%d.' % (SEE_VID_ID, i-imdb._structured_indexes[SEE_VID_ID][0]+1,\n",
    "                                         len(imdb._structured_indexes[SEE_VID_ID])))\n",
    "    data = list(data)\n",
    "    data[0] = data[0].unsqueeze(0)\n",
    "    data[1] = data[1].unsqueeze(0)\n",
    "    data = tuple(data)\n",
    "    #data[2] = data[2].unsqueeze(0)\n",
    "    im_data.data.resize_(data[0].size()).copy_(data[0])\n",
    "    im_info.data.resize_(data[1].size()).copy_(data[1])\n",
    "    #gt_boxes.data.resize_(data[2].size()).copy_(data[2])\n",
    "    #num_boxes.data.resize_(data[3].size()).copy_(data[3])\n",
    "\n",
    "    input = im_data, im_info, template_weights, rois_tracking\n",
    "\n",
    "    det_tic = time.time()\n",
    "    siam_rois, siam_bbox_pred, siam_cls_prob, rois, rois_label, cls_prob, bbox_pred = RCNN(input)\n",
    "\n",
    "    scores = None\n",
    "    pred_boxes = None\n",
    "    \n",
    "    ###########################################\n",
    "    # Get detection boxes.\n",
    "    ###########################################\n",
    "    if cfg.TEST.BBOX_REG:\n",
    "        if rois is not None:\n",
    "            boxes = rois.data[:, :, 1:5]\n",
    "            pred_boxes = bbox_delta_to_pred_boxes(im_info, boxes, bbox_pred)\n",
    "            \n",
    "            pred_rois = pred_boxes[:,4:].view(-1,4)\n",
    "            pred_rois = torch.cat((pred_boxes.new_zeros(pred_rois.size(0),1),pred_rois),dim=1).unsqueeze(0)\n",
    "            bbox_pred, cls_prob, cls_score = RCNN.RCNN.base_feat_to_roi_pred(RCNN.RCNN.base_feat_for_roi, pred_rois, None)\n",
    "            boxes = pred_rois.data[:, :, 1:5]\n",
    "            pred_boxes = bbox_delta_to_pred_boxes(im_info, boxes, bbox_pred)\n",
    "            scores = cls_prob.data\n",
    "            \n",
    "            pred_boxes /= data[1][0][2].item()\n",
    "            scores = scores.squeeze()\n",
    "            pred_boxes = pred_boxes.squeeze()\n",
    "            ###TODO###\n",
    "            # For debug only.\n",
    "            if SEE_DETECTION:\n",
    "                for j in xrange(1, imdb.num_classes):\n",
    "                    inds = torch.nonzero(scores[:,j]>0).view(-1)\n",
    "                    # if there is det\n",
    "                    if inds.numel() > 0:\n",
    "                        cls_scores = scores[:,j][inds]\n",
    "                        _, order = torch.sort(cls_scores, 0, True)\n",
    "                        if args.class_agnostic:\n",
    "                            cls_boxes = pred_boxes[inds, :]\n",
    "                        else:\n",
    "                            cls_boxes = pred_boxes[inds][:, j * 4:(j + 1) * 4]\n",
    "                        cls_dets = torch.cat((cls_boxes, cls_scores.unsqueeze(1)), 1)\n",
    "                        #cls_dets = torch.cat((cls_boxes, cls_scores), 1)\n",
    "                        cls_dets = cls_dets[order]\n",
    "                        ######### nms for each cls here ########\n",
    "                        keep = nms(cls_dets, cfg.TEST.NMS)\n",
    "                        cls_dets = cls_dets[keep.view(-1).long()]\n",
    "                        all_boxes_detection[j][i] = cls_dets.cpu().numpy()\n",
    "                    else:\n",
    "                        all_boxes_detection[j][i] = empty_array\n",
    "            \n",
    "        if siam_bbox_pred is not None:\n",
    "            siam_scores = siam_cls_prob.data\n",
    "            siam_boxes = siam_rois.data[:, 1:5]\n",
    "            pred_siam_bbox = bbox_delta_to_pred_boxes(im_info, siam_boxes.unsqueeze(0), siam_bbox_pred.unsqueeze(0))                                                            \n",
    "            pred_siam_bbox /= data[1][0][2].item()\n",
    "            pred_siam_bbox = pred_siam_bbox.squeeze(0)\n",
    "            # concatenate siambox and detbox.\n",
    "            if MODE==0:\n",
    "                if rois is not None:\n",
    "                    pred_boxes = torch.cat((pred_boxes, pred_siam_bbox), 0)\n",
    "                    scores = torch.cat((scores, siam_scores), 0)\n",
    "                else:\n",
    "                    pred_boxes = pred_siam_bbox\n",
    "                    scores = siam_scores\n",
    "            #####################\n",
    "            if MODE==2:\n",
    "                #####################\n",
    "                #pred_boxes = pred_siam_bbox\n",
    "                #####################\n",
    "                pred_boxes = siam_boxes.repeat(1,siam_boxes.size(1)*31)\n",
    "                pred_boxes = pred_boxes/im_info[0][-1]\n",
    "                scores = siam_scores\n",
    "            ###TODO###\n",
    "            # For debug only.\n",
    "            if SEE_TRACKING:\n",
    "                for j in xrange(1, imdb.num_classes):\n",
    "                    inds = torch.nonzero(siam_scores[:,j]>0).view(-1)\n",
    "                    # if there is det\n",
    "                    if inds.numel() > 0:\n",
    "                        cls_scores = siam_scores[:,j][inds]\n",
    "                        #_, order = torch.sort(cls_scores, 0, True)\n",
    "                        if args.class_agnostic:\n",
    "                            cls_boxes = pred_siam_bbox[inds, :]\n",
    "                        else:\n",
    "                            cls_boxes = pred_siam_bbox[inds][:, j * 4:(j + 1) * 4]\n",
    "                        cls_dets = torch.cat((cls_boxes, cls_scores.unsqueeze(1)), 1)\n",
    "                        # cls_dets = torch.cat((cls_boxes, cls_scores), 1)\n",
    "                        #cls_dets = cls_dets[order]\n",
    "                        ######### nms for each cls here ########\n",
    "                        #keep = nms(cls_dets, cfg.TEST.NMS)\n",
    "                        #cls_dets = cls_dets[keep.view(-1).long()]\n",
    "                        all_boxes_tracking[j][i] = cls_dets.cpu().numpy()\n",
    "                    else:\n",
    "                        all_boxes_tracking[j][i] = empty_array\n",
    "    else:\n",
    "        raise ValueError('Error. Should set cfg.TEST.BBOX_REG to True.')\n",
    "\n",
    "    det_toc = time.time()\n",
    "    detect_time = det_toc - det_tic\n",
    "    misc_tic = time.time()\n",
    "    ###########################################\n",
    "    # NMS for detection and save to all boxes.\n",
    "    ###########################################\n",
    "    if scores is not None:\n",
    "        for j in xrange(1, imdb.num_classes):\n",
    "            inds = torch.nonzero(scores[:,j]>thresh).view(-1)\n",
    "            # if there is det\n",
    "            if inds.numel() > 0:\n",
    "                cls_scores = scores[:,j][inds]\n",
    "                all_scores = scores[inds]\n",
    "                _, order = torch.sort(cls_scores, 0, True)\n",
    "                if args.class_agnostic:\n",
    "                    cls_boxes = pred_boxes[inds, :]\n",
    "                else:\n",
    "                    cls_boxes = pred_boxes[inds][:, j * 4:(j + 1) * 4]\n",
    "                cls_dets = torch.cat((cls_boxes, cls_scores.unsqueeze(1)), 1)\n",
    "                # cls_dets = torch.cat((cls_boxes, cls_scores), 1)\n",
    "                cls_dets = cls_dets[order]\n",
    "                all_scores = all_scores[order]\n",
    "                ######### nms for each cls here ########\n",
    "                keep = nms(cls_dets, cfg.TEST.NMS)\n",
    "                cls_dets = cls_dets[keep.view(-1).long()]\n",
    "                all_cls_scores = all_scores[keep.view(-1).long()]\n",
    "                all_boxes[j][i] = cls_dets.cpu().numpy()\n",
    "                all_boxes_scores[j][i] = all_cls_scores.cpu().numpy()\n",
    "            else:\n",
    "                all_boxes[j][i] = empty_array\n",
    "                all_boxes_scores[j][i] = empty_array\n",
    "    else:\n",
    "        for j in xrange(1, imdb.num_classes):\n",
    "            all_boxes[j][i] = empty_array\n",
    "            all_boxes_scores[j][i] = empty_array\n",
    "\n",
    "    # Limit to max_per_image detections *over all classes*\n",
    "    if max_per_image > 0:\n",
    "        image_scores = np.hstack([all_boxes[j][i][:, -1]\n",
    "                                for j in xrange(1, imdb.num_classes)])\n",
    "        if len(image_scores) > max_per_image:\n",
    "            image_thresh = np.sort(image_scores)[-max_per_image]\n",
    "            for j in xrange(1, imdb.num_classes):\n",
    "                keep = np.where(all_boxes[j][i][:, -1] >= image_thresh)[0]\n",
    "                all_boxes[j][i] = all_boxes[j][i][keep, :]\n",
    "                all_boxes_scores[j][i] = all_boxes_scores[j][i][keep, :]\n",
    "                \n",
    "    # nms between classes.\n",
    "    if cfg.TEST.NMS_CROSS_CLASS > 0.:\n",
    "        cls_boxes = [[]]+[all_boxes[j][i] for j in range(1, imdb.num_classes)]\n",
    "        cls_boxes_scores = [[]]+[all_boxes_scores[j][i] for j in range(1, imdb.num_classes)]\n",
    "        cls_box_list = [cls_boxes[j] for j in range(1, imdb.num_classes) if len(cls_boxes[j])>0]\n",
    "        if len(cls_box_list)>0:\n",
    "            all_dets = np.vstack(cls_box_list)\n",
    "            all_dets_scores = np.vstack([cls_boxes_scores[j] for j in range(1, imdb.num_classes) if len(cls_boxes[j])>0])\n",
    "            class_ids = np.vstack(\n",
    "                [np.ones(shape=(len(cls_boxes[j]), 1))*j for j in range(1, imdb.num_classes) if len(cls_boxes[j])>0])\n",
    "            _inds = np.argsort(-all_dets[:,-1])\n",
    "            all_dets = all_dets[_inds,:]\n",
    "            all_dets_scores = all_dets_scores[_inds,:]\n",
    "            class_ids = class_ids[_inds,:]\n",
    "            \n",
    "            keep = nms(torch.tensor(all_dets.astype(np.float32)).cuda(), cfg.TEST.NMS_CROSS_CLASS).view(-1).long().cpu().numpy()\n",
    "            all_dets = all_dets[keep, :]\n",
    "            all_dets_scores = all_dets_scores[keep, :]\n",
    "            class_ids = class_ids[keep, :]\n",
    "            for j in range(1, imdb.num_classes):\n",
    "                idx_j = np.where(class_ids==j)[0]\n",
    "                all_boxes[j][i] = all_dets[idx_j, :]\n",
    "                all_boxes_scores[j][i] = all_dets_scores[idx_j, :]\n",
    "            \n",
    "    ########\n",
    "    # Get weights for the next iteration.\n",
    "    ########\n",
    "    # First, convert all_boxes to rois_tracking.#\n",
    "    # TODO change threshold.\n",
    "    rois_tracking = prepare_rois_tracking(im_info[0], all_boxes, all_boxes_scores, frame_id=i,\n",
    "                                        class_num=imdb.num_classes, thresh=0.9)\n",
    "    base_feat = RCNN.track_feat_trans_1.cuda()(RCNN.RCNN.Conv_feat_track)\n",
    "    template_weights, rois_tracking = siam_weights_preparation(rois_tracking, base_feat)\n",
    "\n",
    "    misc_toc = time.time()\n",
    "    nms_time = misc_toc - misc_tic\n",
    "\n",
    "    sys.stdout.write('im_detect: {:d}/{:d} {:.3f}s {:.3f}s   \\r' \\\n",
    "      .format(i + 1, num_images, detect_time, nms_time))\n",
    "    sys.stdout.flush()\n",
    "\n",
    "#with open(det_file, 'wb') as f:\n",
    "    #pickle.dump(all_boxes, f, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "#print('Evaluating detections')\n",
    "#imdb.evaluate_detections(all_boxes, output_dir)\n",
    "\n",
    "end = time.time()\n",
    "print(\"test time: %0.4fs\" % (end - start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Examine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(imdb._structured_indexes[SEE_VID_ID][0],imdb._structured_indexes[SEE_VID_ID][-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io as sio\n",
    "devkit_path = 'data/imagenet/ILSVRC/devkit'\n",
    "####VID object info####\n",
    "synsets_video = sio.loadmat(os.path.join(devkit_path,'data','meta_vid.mat'))\n",
    "_wnid = (0,)\n",
    "_classes = ('__background__',)\n",
    "for i in xrange(30):\n",
    "    _classes = _classes + (synsets_video['synsets'][0][i][2][0],)\n",
    "    _wnid = _wnid + (synsets_video['synsets'][0][i][1][0],)\n",
    "\n",
    "_wnid_to_ind = dict(zip(_wnid, xrange(31)))\n",
    "_class_to_ind = dict(zip(_classes, xrange(31)))\n",
    "#######################\n",
    "def read_annotation(dataPath):\n",
    "    filename = dataPath.replace('Data','Annotations').replace('JPEG','xml')\n",
    "    assert os.path.exists(filename),'%s'%(filename)\n",
    "    # print 'Loading: {}'.format(filename)\n",
    "    def get_data_from_tag(node, tag):\n",
    "        return node.getElementsByTagName(tag)[0].childNodes[0].data\n",
    "\n",
    "    with open(filename) as f:\n",
    "        data = minidom.parseString(f.read())\n",
    "\n",
    "    objs = data.getElementsByTagName('object')\n",
    "    num_objs = len(objs)\n",
    "    \n",
    "    boxes = np.zeros((num_objs, 4), dtype=np.int32)\n",
    "    gt_classes = np.zeros(num_objs,dtype=np.int32)\n",
    "    # Load object bounding boxes into a data frame.\n",
    "    for ix, obj in enumerate(objs):\n",
    "        x1 = float(get_data_from_tag(obj, 'xmin'))\n",
    "        y1 = float(get_data_from_tag(obj, 'ymin'))\n",
    "        x2 = float(get_data_from_tag(obj, 'xmax'))\n",
    "        y2 = float(get_data_from_tag(obj, 'ymax'))\n",
    "        cls = _wnid_to_ind[\n",
    "                str(get_data_from_tag(obj, \"name\")).lower().strip()]\n",
    "        boxes[ix, :] = [x1, y1, x2, y2]\n",
    "        gt_classes[ix] = cls\n",
    "    return boxes, gt_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def showBoxResult(img_id, all_boxes, imdb, show_class=True, threshold=0.3, dpi = 200,all_boxes_tracking=None):\n",
    "    imIdx = imdb.image_index[img_id]+'.JPEG'\n",
    "    assert os.path.exists(imIdx), imIdx+' does not exist.'\n",
    "    #print(imIdx)\n",
    "    gt_boxes, gt_classes = read_annotation(imIdx)\n",
    "    im2show = np.array(PIL.Image.open(imIdx))\n",
    "    fig = plt.figure(frameon=False)\n",
    "    fig.set_size_inches(im2show.shape[1] / dpi, im2show.shape[0] / dpi)\n",
    "    ax = plt.Axes(fig, [0., 0., 1., 1.])\n",
    "    ax.axis('off')\n",
    "    fig.add_axes(ax)\n",
    "    ax.imshow(im2show)\n",
    "    \n",
    "    #draw gt first\n",
    "    for j in range(len(gt_classes)):\n",
    "        ax.add_patch(\n",
    "        plt.Rectangle((gt_boxes[j][0], gt_boxes[j][1]),\n",
    "                      gt_boxes[j][2] - gt_boxes[j][0],\n",
    "                      gt_boxes[j][3] - gt_boxes[j][1],\n",
    "                      fill=False, edgecolor='g',\n",
    "                      linewidth=2.0, alpha=0.8))\n",
    "        if show_class:\n",
    "            ax.text(gt_boxes[j][0], gt_boxes[j][1] - 2,\n",
    "            '%s %f'%(imdb.classes[gt_classes[j]], 1.0),\n",
    "            fontsize=10,\n",
    "            #family='serif',\n",
    "            bbox=dict(facecolor='g', alpha=0.5, pad=0, edgecolor='none'),\n",
    "                color='white')\n",
    " \n",
    "    #draw dets\n",
    "    for j in range(len(imdb.classes)):\n",
    "        if isinstance(all_boxes[j][img_id], np.ndarray):\n",
    "            for bbox in all_boxes[j][img_id]:\n",
    "                if bbox[-1]>threshold:\n",
    "                    ax.add_patch(\n",
    "                    plt.Rectangle((bbox[0], bbox[1]),\n",
    "                              bbox[2] - bbox[0],\n",
    "                              bbox[3] - bbox[1],\n",
    "                              fill=False, edgecolor='y',\n",
    "                              linewidth=2.0, alpha=0.4))\n",
    "                    if show_class:\n",
    "                        ax.text(bbox[0], bbox[1] - 2,\n",
    "                        '%s %f'%(imdb.classes[j], bbox[-1]),\n",
    "                        fontsize=10,\n",
    "                        #family='serif',\n",
    "                        bbox=dict(\n",
    "                            facecolor='y', alpha=0.5, pad=0, edgecolor='none'),\n",
    "                            color='white')\n",
    "            #im2show = vis_detections(im2show, imdb.classes[j], all_boxes[j][img_id], 0.3)\n",
    "    #plt.show()\n",
    "    if all_boxes_detection is not None:\n",
    "        for j in range(len(imdb.classes)):\n",
    "            if isinstance(all_boxes_detection[j][img_id], np.ndarray):\n",
    "                for bbox in all_boxes_detection[j][img_id]:\n",
    "                    if bbox[-1]>threshold:\n",
    "                        ax.add_patch(\n",
    "                        plt.Rectangle((bbox[0], bbox[1]),\n",
    "                                  bbox[2] - bbox[0],\n",
    "                                  bbox[3] - bbox[1],\n",
    "                                  fill=False, edgecolor='m',\n",
    "                                  linewidth=2.0, alpha=0.2))\n",
    "                        if show_class:\n",
    "                            ax.text(bbox[0], bbox[1] - 2,\n",
    "                            '%s %f'%(imdb.classes[j], bbox[-1]),\n",
    "                            fontsize=10,\n",
    "                            #family='serif',\n",
    "                            bbox=dict(\n",
    "                                facecolor='m', alpha=0.2, pad=0, edgecolor='none'),\n",
    "                                color='white')\n",
    "    \n",
    "    if all_boxes_tracking is not None:\n",
    "        for j in range(len(imdb.classes)):\n",
    "            if isinstance(all_boxes_tracking[j][img_id], np.ndarray):\n",
    "                for bbox in all_boxes_tracking[j][img_id]:\n",
    "                    if bbox[-1]>threshold:\n",
    "                        ax.add_patch(\n",
    "                        plt.Rectangle((bbox[0], bbox[1]),\n",
    "                                  bbox[2] - bbox[0],\n",
    "                                  bbox[3] - bbox[1],\n",
    "                                  fill=False, edgecolor='w',\n",
    "                                  linewidth=2.0, alpha=0.4))\n",
    "                        if show_class:\n",
    "                            ax.text(bbox[0], bbox[1] - 2,\n",
    "                            '%s %f'%(imdb.classes[j], bbox[-1]),\n",
    "                            fontsize=10,\n",
    "                            #family='serif',\n",
    "                            bbox=dict(\n",
    "                                facecolor='w', alpha=0.5, pad=0, edgecolor='none'),\n",
    "                                color='white')\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def makeVid(imdb,all_boxes,img_ids,vid_id,dname_prefix='output/tmp_vid',dir_suffix='',ext='png',all_boxes_tracking=None):\n",
    "    name_ls = []\n",
    "    dname = dname_prefix+'_%03d'%(vid_id)+dir_suffix\n",
    "    if not os.path.exists(dname):\n",
    "        os.mkdir(dname)\n",
    "        assert os.path.exists(dname)\n",
    "    for i in img_ids:\n",
    "        fname = os.path.join(dname,'%08d'%(i)+'.'+ext)\n",
    "        fig = showBoxResult(i,all_boxes,imdb,all_boxes_tracking=all_boxes_tracking)\n",
    "        fig.savefig(fname)\n",
    "        plt.close(fig)\n",
    "        name_ls.append(fname)\n",
    "    return name_ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_ids = imdb._structured_indexes[SEE_VID_ID]\n",
    "dir_suffix = ''\n",
    "if MODE==1:\n",
    "    dir_suffix='_det'\n",
    "elif MODE==2:\n",
    "    dir_suffix='_tra'\n",
    "name_ls = makeVid(imdb,all_boxes,img_ids,SEE_VID_ID,dname_prefix='output/tmp_vid',dir_suffix=dir_suffix,ext='pdf',all_boxes_tracking=all_boxes_tracking)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge all images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PyPDF2 import PdfFileMerger\n",
    "\n",
    "pdfs = name_ls\n",
    "merger = PdfFileMerger()\n",
    "\n",
    "for pdf in pdfs:\n",
    "    merger.append(open(pdf, 'rb'))\n",
    "\n",
    "with open(os.path.join(os.path.dirname(pdfs[0]),'result.pdf'), 'wb') as fout:\n",
    "    merger.write(fout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(os.path.join(os.path.dirname(pdfs[0]),'result.pdf'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
