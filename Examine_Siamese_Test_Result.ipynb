{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "import cPickle\n",
      "import cPickle\n",
      "import cPickle\n",
      "import cPickle\n",
      "import cPickle\n",
      "import cPickle\n"
     ]
    }
   ],
   "source": [
    "# --------------------------------------------------------\n",
    "# Tensorflow Faster R-CNN\n",
    "# Licensed under The MIT License [see LICENSE for details]\n",
    "# Written by Jiasen Lu, Jianwei Yang, based on code from Ross Girshick\n",
    "# --------------------------------------------------------\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "from easydict import EasyDict\n",
    "import _init_paths\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import argparse\n",
    "import pprint\n",
    "import pdb\n",
    "import time\n",
    "import cv2\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import xml.dom.minidom as minidom\n",
    "import PIL\n",
    "from PIL import Image\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "from matplotlib import pyplot as plt\n",
    "try:\n",
    "    import cPickle as pickle\n",
    "    print('import cPickle')\n",
    "except:\n",
    "    import pickle\n",
    "    print('import python pickle')\n",
    "from roi_data_layer.roidb import combined_roidb\n",
    "from roi_data_layer.roibatchLoader import roibatchLoader\n",
    "from model.utils.config import cfg, cfg_from_file, cfg_from_list, get_output_dir\n",
    "from model.rpn.bbox_transform import clip_boxes\n",
    "from model.nms.nms_wrapper import nms\n",
    "from model.rpn.bbox_transform import bbox_transform_inv\n",
    "from model.utils.net_utils import save_net, load_net, vis_detections\n",
    "from model.faster_rcnn.vgg16 import vgg16\n",
    "from model.faster_rcnn.resnet import resnet\n",
    "#from model.faster_rcnn.faster_rcnn import _fasterRCNN\n",
    "from model.siamese_net.siameseRCNN import _siameseRCNN\n",
    "from model.siamese_net.weight_cropping_layer import weight_crop_layer\n",
    "\n",
    "import pdb\n",
    "\n",
    "try:\n",
    "    xrange          # Python 2\n",
    "except NameError:\n",
    "    xrange = range  # Python 3\n",
    "\n",
    "torch.cuda.set_device(0)\n",
    "def parse_args():\n",
    "    \"\"\"\n",
    "    Parse input arguments\n",
    "    \"\"\"\n",
    "    args = EasyDict()\n",
    "    args['dataset'] = 'imagenetVID_PLUS'\n",
    "    args['net'] = 'res101'\n",
    "    args['load_dir'] = 'models'\n",
    "    args['cuda'] = True\n",
    "    args['vid_size'] = 1\n",
    "    args['class_agnostic'] = False\n",
    "    args['cfg_file'] = 'cfgs/res101_lighthead_siam.yml'\n",
    "    args['ckpt'] = '1_5_27134'\n",
    "    return args\n",
    "\n",
    "\n",
    "def bbox_delta_to_pred_boxes(im_info, boxes, bbox_pred):\n",
    "    box_deltas = bbox_pred.data\n",
    "    if cfg.TRAIN.BBOX_NORMALIZE_TARGETS_PRECOMPUTED:\n",
    "        # Optionally normalize targets by a precomputed mean and stdev\n",
    "        if args.class_agnostic:\n",
    "            box_deltas = box_deltas.view(-1, 4) * torch.FloatTensor(cfg.TRAIN.BBOX_NORMALIZE_STDS).cuda() \\\n",
    "                         + torch.FloatTensor(cfg.TRAIN.BBOX_NORMALIZE_MEANS).cuda()\n",
    "            box_deltas = box_deltas.view(1, -1, 4)\n",
    "        else:\n",
    "            box_deltas = box_deltas.view(-1, 4) * torch.FloatTensor(cfg.TRAIN.BBOX_NORMALIZE_STDS).cuda() \\\n",
    "                         + torch.FloatTensor(cfg.TRAIN.BBOX_NORMALIZE_MEANS).cuda()\n",
    "            box_deltas = box_deltas.view(1, -1, 4 * len(imdb.classes))\n",
    "\n",
    "    pred_boxes = bbox_transform_inv(boxes, box_deltas, 1)\n",
    "    pred_boxes = clip_boxes(pred_boxes, im_info.data, 1)\n",
    "    return pred_boxes\n",
    "\n",
    "weight_cropper = weight_crop_layer().cuda()\n",
    "def siam_weights_preparation(rois_tracking, base_feat):\n",
    "    if rois_tracking is None:\n",
    "        return None, None\n",
    "    else:\n",
    "        rois_tracking = Variable(base_feat.new_tensor(rois_tracking))\n",
    "        boxes = rois_tracking[:,:4]\n",
    "        batch_inds = boxes.new_zeros((boxes.size(0),1))\n",
    "        boxes = torch.cat((batch_inds, boxes),dim=1)\n",
    "        template_weights = weight_cropper(base_feat, boxes)\n",
    "        return template_weights, rois_tracking\n",
    "\n",
    "def prepare_rois_tracking(im_info, all_boxes, all_boxes_scores, frame_id, class_num, thresh=cfg.SIAMESE.THRESH_FOR_TRACKING):\n",
    "    # class_num is 31 for imagenetVID.\n",
    "    sel_boxes = []\n",
    "    for j in range(1, class_num):\n",
    "        if len(all_boxes[j][frame_id]) == 0:\n",
    "            continue\n",
    "        scored_boxes = all_boxes[j][frame_id].copy()\n",
    "        scores = all_boxes_scores[j][frame_id].copy()\n",
    "        assert len(scored_boxes)==len(scores), 'length of scored_boxes and length of scores should be the equal.'\n",
    "        # TODO comment out the following for loop to accelerate predictions.\n",
    "        scored_boxes[:, :4] = scored_boxes[:, :4] * im_info[-1]\n",
    "        for b_id in range(len(scored_boxes)):\n",
    "            assert scored_boxes[b_id, 4] == scores[b_id, j], 'scores not matched, please check your code.'\n",
    "        inds = np.where(scored_boxes[:, 4]>thresh)[0]\n",
    "        if len(inds)>0:\n",
    "            sel_cls_boxes = np.concatenate((scored_boxes[inds,:4], scores[inds,:]), axis=1)\n",
    "            sel_boxes.append(sel_cls_boxes)\n",
    "        else:\n",
    "            continue\n",
    "    if len(sel_boxes)>0:\n",
    "        rois_tracking = np.concatenate(sel_boxes, axis=0)\n",
    "    else:\n",
    "        rois_tracking = None\n",
    "    return rois_tracking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Called with args:\n",
      "{'load_dir': 'models', 'vid_size': 1, 'dataset': 'imagenetVID_PLUS', 'ckpt': '1_5_27134', 'cuda': True, 'cfg_file': 'cfgs/res101_lighthead_siam.yml', 'net': 'res101', 'class_agnostic': False}\n",
      "Using config:\n",
      "{'ANCHOR_RATIOS': [0.5, 1, 2],\n",
      " 'ANCHOR_SCALES': [4, 8, 16, 32],\n",
      " 'CROP_RESIZE_WITH_MAX_POOL': False,\n",
      " 'CUDA': True,\n",
      " 'DATA_DIR': '/home/lvye/lvye/VODProj/faster-rcnn.pytorch/data',\n",
      " 'DEDUP_BOXES': 0.0625,\n",
      " 'EPS': 1e-14,\n",
      " 'EXP_DIR': 'res101',\n",
      " 'FEAT_STRIDE': [16],\n",
      " 'GPU_ID': 0,\n",
      " 'MATLAB': 'matlab',\n",
      " 'MAX_NUM_GT_BOXES': 30,\n",
      " 'MOBILENET': {'DEPTH_MULTIPLIER': 1.0,\n",
      "               'FIXED_LAYERS': 5,\n",
      "               'REGU_DEPTH': False,\n",
      "               'WEIGHT_DECAY': 4e-05},\n",
      " 'PIXEL_MEANS': array([[[102.9801, 115.9465, 122.7717]]]),\n",
      " 'POOLING_MODE': 'pspool',\n",
      " 'POOLING_SIZE': 7,\n",
      " 'RESNET': {'CORE_CHOICE': {'FASTER_RCNN': 'faster_rcnn',\n",
      "                            'RFCN': 'rfcn',\n",
      "                            'RFCN_LIGHTHEAD': 'rfcn_light_head',\n",
      "                            'USE': 'rfcn_light_head'},\n",
      "            'FIXED_BLOCKS': 1,\n",
      "            'MAX_POOL': False},\n",
      " 'RNG_SEED': 3,\n",
      " 'ROOT_DIR': '/home/lvye/lvye/VODProj/faster-rcnn.pytorch',\n",
      " 'SIAMESE': {'ANCHOR_RATIOS': [0.5, 1, 2],\n",
      "             'ANCHOR_SCALES': [4, 8, 16, 32],\n",
      "             'CROP_TYPE': 'center_crop',\n",
      "             'DETACH_CONV1234': False,\n",
      "             'DETACH_FEAT': False,\n",
      "             'DET_WEIGHT': 0.0,\n",
      "             'FG_FRACTION': 1.0,\n",
      "             'HANNING_WINDOW_SIZE_FACTOR': 1.0,\n",
      "             'HANNING_WINDOW_WEIGHT': 1.0,\n",
      "             'NORMALIZE_CORRELATION': False,\n",
      "             'NUM_CHANNELS_FOR_CORRELATION': 256,\n",
      "             'PANELTY_K': 0.2,\n",
      "             'RPN_BATCH_SIZE': 256,\n",
      "             'RPN_NEGATIVE_OVERLAP_HI': 0.4,\n",
      "             'RPN_NEGATIVE_OVERLAP_LO': 0.0,\n",
      "             'RPN_NMS_THRESH': 0.7,\n",
      "             'RPN_POSITIVE_OVERLAP': 0.6,\n",
      "             'TEMPLATE_GEN_FROM_GT_ITERS': 0,\n",
      "             'TEMPLATE_SEL_BATCH_SIZE': 128,\n",
      "             'TEMPLATE_SEL_BG_THRESH_HI': 0.1,\n",
      "             'TEMPLATE_SEL_BG_THRESH_LO': 0.1,\n",
      "             'TEMPLATE_SEL_CLS_THRESH': 0.8,\n",
      "             'TEMPLATE_SEL_FG_THRESH': 0.6,\n",
      "             'TEMPLATE_SZ': 3,\n",
      "             'THRESH_FOR_TRACKING': 0.8,\n",
      "             'USE_DCN': False,\n",
      "             'USE_POS_PRIOR_FOR_SEL': True,\n",
      "             'USE_SEPARABLE_CORRELATION': False,\n",
      "             'WEIGHT_CROPPING_LAYER_SCALE': 0.0625},\n",
      " 'TEST': {'BBOX_REG': True,\n",
      "          'HAS_RPN': True,\n",
      "          'MAX_SIZE': 1000,\n",
      "          'MODE': 'nms',\n",
      "          'NMS': 0.3,\n",
      "          'PROPOSAL_METHOD': 'gt',\n",
      "          'RPN_MIN_SIZE': 16,\n",
      "          'RPN_NMS_THRESH': 0.7,\n",
      "          'RPN_POST_NMS_TOP_N': 300,\n",
      "          'RPN_PRE_NMS_TOP_N': 6000,\n",
      "          'RPN_TOP_N': 5000,\n",
      "          'SCALES': [768],\n",
      "          'SIAMESE_RPN_MIN_SIZE': 8,\n",
      "          'SIAMESE_RPN_NMS_THRESH': 0.7,\n",
      "          'SIAMESE_RPN_POST_NMS_TOP_N': 300,\n",
      "          'SIAMESE_RPN_PRE_NMS_TOP_N': 6000,\n",
      "          'SVM': False},\n",
      " 'TRAIN': {'ASPECT_GROUPING': False,\n",
      "           'BATCH_SIZE': 128,\n",
      "           'BBOX_INSIDE_WEIGHTS': [1.0, 1.0, 1.0, 1.0],\n",
      "           'BBOX_NORMALIZE_MEANS': [0.0, 0.0, 0.0, 0.0],\n",
      "           'BBOX_NORMALIZE_STDS': [0.1, 0.1, 0.2, 0.2],\n",
      "           'BBOX_NORMALIZE_TARGETS': True,\n",
      "           'BBOX_NORMALIZE_TARGETS_PRECOMPUTED': True,\n",
      "           'BBOX_REG': True,\n",
      "           'BBOX_THRESH': 0.5,\n",
      "           'BG_THRESH_HI': 0.5,\n",
      "           'BG_THRESH_LO': 0.0,\n",
      "           'BIAS_DECAY': False,\n",
      "           'BN_TRAIN': False,\n",
      "           'DISPLAY': 20,\n",
      "           'DOUBLE_BIAS': False,\n",
      "           'FG_FRACTION': 0.25,\n",
      "           'FG_THRESH': 0.5,\n",
      "           'GAMMA': 0.1,\n",
      "           'HAS_RPN': True,\n",
      "           'IMS_PER_BATCH': 1,\n",
      "           'LEARNING_RATE': 0.001,\n",
      "           'LOWER_BOUND': 1.0,\n",
      "           'MAX_SIZE': 1000,\n",
      "           'MOMENTUM': 0.9,\n",
      "           'OHEM': False,\n",
      "           'OHEM_BATCH_SIZE': 128,\n",
      "           'OHEM_NMS': 0.7,\n",
      "           'PROPOSAL_METHOD': 'gt',\n",
      "           'RPN_BATCHSIZE': 256,\n",
      "           'RPN_BBOX_INSIDE_WEIGHTS': [1.0, 1.0, 1.0, 1.0],\n",
      "           'RPN_CLOBBER_POSITIVES': False,\n",
      "           'RPN_FG_FRACTION': 0.5,\n",
      "           'RPN_MIN_SIZE': 8,\n",
      "           'RPN_NEGATIVE_OVERLAP': 0.3,\n",
      "           'RPN_NMS_THRESH': 0.7,\n",
      "           'RPN_POSITIVE_OVERLAP': 0.7,\n",
      "           'RPN_POSITIVE_WEIGHT': -1.0,\n",
      "           'RPN_POST_NMS_TOP_N': 2000,\n",
      "           'RPN_PRE_NMS_TOP_N': 12000,\n",
      "           'SCALES': [768],\n",
      "           'SIAMESE_MAX_TRACKING_OBJ': 10,\n",
      "           'SIAMESE_ONLY': False,\n",
      "           'SIAMESE_RPN_MIN_SIZE': 8,\n",
      "           'SIAMESE_RPN_NMS_THRESH': 0.7,\n",
      "           'SIAMESE_RPN_POST_NMS_TOP_N': 2000,\n",
      "           'SIAMESE_RPN_PRE_NMS_TOP_N': 12000,\n",
      "           'SNAPSHOT_ITERS': 5000,\n",
      "           'SNAPSHOT_KEPT': 3,\n",
      "           'SNAPSHOT_PREFIX': 'res101_faster_rcnn',\n",
      "           'STEPSIZE': [30000],\n",
      "           'SUMMARY_INTERVAL': 180,\n",
      "           'TRIM_HEIGHT': 768,\n",
      "           'TRIM_WIDTH': 768,\n",
      "           'TRUNCATED': False,\n",
      "           'UPPER_BOUND': 1.0,\n",
      "           'USE_ALL_GT': True,\n",
      "           'USE_FLIPPED': False,\n",
      "           'USE_GT': False,\n",
      "           'WEIGHT_DECAY': 0.0001},\n",
      " 'USE_GPU_NMS': True}\n",
      "Total number of videos are: 555.\n",
      "Total number of video images are: 176126.\n",
      "Loaded dataset `imagenetVID_PLUS_val` for training\n",
      "Set proposal method: gt\n",
      "Preparing training data...\n",
      "/home/lvye/lvye/VODProj/faster-rcnn.pytorch/data/cache/imagenetVID_PLUS_val_gt_roidb.pkl\n",
      "imagenetVID_PLUS_val gt roidb loaded from /home/lvye/lvye/VODProj/faster-rcnn.pytorch/data/cache/imagenetVID_PLUS_val_gt_roidb.pkl\n",
      "Image sizes loaded from /home/lvye/lvye/VODProj/faster-rcnn.pytorch/data/cache/imagenetVID_PLUS_val_sizes.pkl\n",
      "176126\n",
      "176126\n",
      "done\n",
      "Total number of videos are: 555.\n",
      "Total number of video images are: 176126.\n",
      "176126 roidb entries\n",
      "RCNN uses RFCN Light Head core.\n",
      "Loading pretrained weights from data/pretrained_model/resnet101_caffe.pth\n",
      "load checkpoint models/res101/imagenetVID_PLUS/rfcn_light_head_siam_1_5_27134.pth\n",
      "load model successfully!\n"
     ]
    }
   ],
   "source": [
    "args = parse_args()\n",
    "\n",
    "print('Called with args:')\n",
    "print(args)\n",
    "\n",
    "if torch.cuda.is_available() and not args.cuda:\n",
    "    print(\"WARNING: You have a CUDA device, so you should probably run with --cuda\")\n",
    "\n",
    "np.random.seed(cfg.RNG_SEED)\n",
    "if args.dataset == \"imagenetVID\":\n",
    "    args.imdb_name = 'imagenetVID_train'\n",
    "    args.imdbval_name = 'imagenetVID_val'\n",
    "    args.set_cfgs = ['ANCHOR_SCALES', '[4, 8, 16, 32]', 'ANCHOR_RATIOS', '[0.5,1,2]', 'MAX_NUM_GT_BOXES', '30']\n",
    "elif args.dataset == \"imagenetVID_PLUS\":\n",
    "    args.imdb_name = 'imagenetVID_PLUS_train'\n",
    "    args.imdbval_name = 'imagenetVID_PLUS_val'\n",
    "    args.set_cfgs = ['ANCHOR_SCALES', '[4, 8, 16, 32]', 'ANCHOR_RATIOS', '[0.5,1,2]', 'MAX_NUM_GT_BOXES', '30']\n",
    "elif args.dataset == \"imagenetVID_1_vid\":\n",
    "    args.imdb_name = 'imagenetVID_1_vid_train'\n",
    "    # TODO imdbval is set to train set now.\n",
    "    args.imdbval_name = 'imagenetVID_1_vid_train'\n",
    "    args.set_cfgs = ['ANCHOR_SCALES', '[4, 8, 16, 32]', 'ANCHOR_RATIOS', '[0.5,1,2]', 'MAX_NUM_GT_BOXES', '30']\n",
    "\n",
    "if args.cfg_file is None:\n",
    "    args.cfg_file = \"cfgs/{}_ls.yml\".format(args.net) if args.large_scale else \"cfgs/{}.yml\".format(args.net)\n",
    "\n",
    "if args.cfg_file is not None:\n",
    "    cfg_from_file(args.cfg_file)\n",
    "if args.set_cfgs is not None:\n",
    "    cfg_from_list(args.set_cfgs)\n",
    "\n",
    "print('Using config:')\n",
    "pprint.pprint(cfg)\n",
    "\n",
    "cfg.TRAIN.USE_FLIPPED = False\n",
    "imdb, roidb, ratio_list, ratio_index = combined_roidb(args.imdbval_name, False)\n",
    "imdb.competition_mode(on=True)\n",
    "\n",
    "print('{:d} roidb entries'.format(len(roidb)))\n",
    "\n",
    "input_dir = args.load_dir + \"/\" + args.net + \"/\" + args.dataset\n",
    "if not os.path.exists(input_dir):\n",
    "    raise Exception('There is no input directory for loading network from ' + input_dir)\n",
    "\n",
    "#print('cfg.RESNET.CORE_CHOICE.USE:',cfg.RESNET.CORE_CHOICE.USE)\n",
    "load_name_predix = cfg.RESNET.CORE_CHOICE.USE + '_siam'\n",
    "if cfg.TRAIN.OHEM is True:\n",
    "    load_name_predix = load_name_predix+'_OHEM'\n",
    "load_name = os.path.join(input_dir, load_name_predix+'_{}.pth'.format(args.ckpt))\n",
    "\n",
    "# initilize the network here.\n",
    "if args.net == 'res101':\n",
    "    RCNN = _siameseRCNN(imdb.classes, args)\n",
    "else:\n",
    "    print(\"network is not defined\")\n",
    "    pdb.set_trace()\n",
    "\n",
    "print(\"load checkpoint %s\" % (load_name))\n",
    "checkpoint = torch.load(load_name)\n",
    "RCNN.load_state_dict(checkpoint['model'])\n",
    "if 'pooling_mode' in checkpoint.keys():\n",
    "    cfg.POOLING_MODE = checkpoint['pooling_mode']\n",
    "\n",
    "\n",
    "print('load model successfully!')\n",
    "# initilize the tensor holder here.\n",
    "im_data = torch.FloatTensor(1)\n",
    "im_info = torch.FloatTensor(1)\n",
    "num_boxes = torch.LongTensor(1)\n",
    "gt_boxes = torch.FloatTensor(1)\n",
    "\n",
    "# ship to cuda\n",
    "if args.cuda:\n",
    "    im_data = im_data.cuda()\n",
    "    im_info = im_info.cuda()\n",
    "    num_boxes = num_boxes.cuda()\n",
    "    gt_boxes = gt_boxes.cuda()\n",
    "\n",
    "# make variable\n",
    "im_data = Variable(im_data)\n",
    "im_info = Variable(im_info)\n",
    "num_boxes = Variable(num_boxes)\n",
    "gt_boxes = Variable(gt_boxes)\n",
    "\n",
    "if args.cuda:\n",
    "    cfg.CUDA = True\n",
    "\n",
    "if args.cuda:\n",
    "    RCNN.cuda()\n",
    "\n",
    "start = time.time()\n",
    "max_per_image = 100\n",
    "\n",
    "thresh = 0.01\n",
    "\n",
    "#save_name = 'light_head_rcnn_10'\n",
    "save_name = load_name_predix\n",
    "num_images = len(imdb.image_index)\n",
    "\n",
    "output_dir = get_output_dir(imdb, save_name)\n",
    "dataset = roibatchLoader(roidb, ratio_list, ratio_index, 1, \\\n",
    "                    imdb.num_classes, training=False, normalize = False)\n",
    "#dataloader = torch.utils.data.DataLoader(dataset, batch_size=1,\n",
    "#                        shuffle=False, num_workers=0,\n",
    "#                        pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_boxes = [[[] for _ in xrange(num_images)]\n",
    "           for _ in xrange(imdb.num_classes)]\n",
    "all_boxes_scores = [[[] for _ in xrange(num_images)]\n",
    "                   for _ in xrange(imdb.num_classes)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEE_VID_ID = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0 det+tra; 1 det; 2 tra\n",
    "MODE = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing vid 1: 1/464.\n",
      "Processing vid 1: 2/464.138s 0.048s   \n",
      "Processing vid 1: 3/464.186s 0.051s   \n",
      "Processing vid 1: 4/464.178s 0.037s   \n",
      "Processing vid 1: 5/464.166s 0.040s   \n",
      "Processing vid 1: 6/464.174s 0.048s   \n",
      "Processing vid 1: 7/464.168s 0.038s   \n",
      "Processing vid 1: 8/464.187s 0.040s   \n",
      "Processing vid 1: 9/464.180s 0.042s   \n",
      "Processing vid 1: 10/464.76s 0.038s   \n",
      "Processing vid 1: 11/464.65s 0.035s   \n",
      "Processing vid 1: 12/464.76s 0.042s   \n",
      "Processing vid 1: 13/464.72s 0.042s   \n",
      "Processing vid 1: 14/464.78s 0.045s   \n",
      "Processing vid 1: 15/464.69s 0.041s   \n",
      "Processing vid 1: 16/464.77s 0.038s   \n",
      "Processing vid 1: 17/464.94s 0.044s   \n",
      "Processing vid 1: 18/464.89s 0.037s   \n",
      "Processing vid 1: 19/464.80s 0.059s   \n",
      "Processing vid 1: 20/464.89s 0.040s   \n",
      "Processing vid 1: 21/464.75s 0.034s   \n",
      "Processing vid 1: 22/464.76s 0.038s   \n",
      "Processing vid 1: 23/464.81s 0.037s   \n",
      "Processing vid 1: 24/464.86s 0.037s   \n",
      "Processing vid 1: 25/464.77s 0.036s   \n",
      "Processing vid 1: 26/464.68s 0.033s   \n",
      "Processing vid 1: 27/464.77s 0.035s   \n",
      "Processing vid 1: 28/464.03s 0.042s   \n",
      "Processing vid 1: 29/464.70s 0.035s   \n",
      "Processing vid 1: 30/464.72s 0.035s   \n",
      "Processing vid 1: 31/464.91s 0.035s   \n",
      "Processing vid 1: 32/464.67s 0.033s   \n",
      "Processing vid 1: 33/464.72s 0.042s   \n",
      "Processing vid 1: 34/464.78s 0.036s   \n",
      "Processing vid 1: 35/464.77s 0.035s   \n",
      "Processing vid 1: 36/464.84s 0.053s   \n",
      "Processing vid 1: 37/464.77s 0.043s   \n",
      "Processing vid 1: 38/464.79s 0.037s   \n",
      "Processing vid 1: 39/464.85s 0.047s   \n",
      "Processing vid 1: 40/464.80s 0.042s   \n",
      "Processing vid 1: 41/464.75s 0.046s   \n",
      "Processing vid 1: 42/464.95s 0.049s   \n",
      "Processing vid 1: 43/464.82s 0.045s   \n",
      "Processing vid 1: 44/464.74s 0.043s   \n",
      "Processing vid 1: 45/464.81s 0.044s   \n",
      "Processing vid 1: 46/464.78s 0.040s   \n",
      "Processing vid 1: 47/464.76s 0.043s   \n",
      "Processing vid 1: 48/464.73s 0.039s   \n",
      "Processing vid 1: 49/464.76s 0.039s   \n",
      "Processing vid 1: 50/464.85s 0.048s   \n",
      "Processing vid 1: 51/464.83s 0.045s   \n",
      "Processing vid 1: 52/464.82s 0.042s   \n",
      "Processing vid 1: 53/464.77s 0.039s   \n",
      "Processing vid 1: 54/464.75s 0.040s   \n",
      "Processing vid 1: 55/464.89s 0.039s   \n",
      "Processing vid 1: 56/464.70s 0.043s   \n",
      "Processing vid 1: 57/464.79s 0.035s   \n",
      "Processing vid 1: 58/464.72s 0.039s   \n",
      "Processing vid 1: 59/464.01s 0.045s   \n",
      "Processing vid 1: 60/464.82s 0.041s   \n",
      "Processing vid 1: 61/464.90s 0.047s   \n",
      "Processing vid 1: 62/464.70s 0.043s   \n",
      "Processing vid 1: 63/464.10s 0.038s   \n",
      "Processing vid 1: 64/464.71s 0.046s   \n",
      "Processing vid 1: 65/464.76s 0.037s   \n",
      "Processing vid 1: 66/464.83s 0.043s   \n",
      "Processing vid 1: 67/464.93s 0.040s   \n",
      "Processing vid 1: 68/464.70s 0.037s   \n",
      "Processing vid 1: 69/464.77s 0.035s   \n",
      "Processing vid 1: 70/464.86s 0.037s   \n",
      "Processing vid 1: 71/464.81s 0.042s   \n",
      "Processing vid 1: 72/464.98s 0.038s   \n",
      "Processing vid 1: 73/464.85s 0.037s   \n",
      "Processing vid 1: 74/464.75s 0.038s   \n",
      "Processing vid 1: 75/464.78s 0.038s   \n",
      "Processing vid 1: 76/464.83s 0.045s   \n",
      "Processing vid 1: 77/464.75s 0.046s   \n",
      "Processing vid 1: 78/464.74s 0.039s   \n",
      "Processing vid 1: 79/464.78s 0.037s   \n",
      "Processing vid 1: 80/464.80s 0.033s   \n",
      "Processing vid 1: 81/464.77s 0.037s   \n",
      "Processing vid 1: 82/464.75s 0.034s   \n",
      "Processing vid 1: 83/464.94s 0.037s   \n",
      "Processing vid 1: 84/464.78s 0.035s   \n",
      "Processing vid 1: 85/464.73s 0.038s   \n",
      "Processing vid 1: 86/464.94s 0.044s   \n",
      "Processing vid 1: 87/464.89s 0.040s   \n",
      "Processing vid 1: 88/464.88s 0.048s   \n",
      "Processing vid 1: 89/464.80s 0.036s   \n",
      "Processing vid 1: 90/464.98s 0.050s   \n",
      "Processing vid 1: 91/464.74s 0.037s   \n",
      "Processing vid 1: 92/464.80s 0.037s   \n",
      "Processing vid 1: 93/464.84s 0.034s   \n",
      "Processing vid 1: 94/464.76s 0.035s   \n",
      "Processing vid 1: 95/464.83s 0.039s   \n",
      "Processing vid 1: 96/464.83s 0.043s   \n",
      "Processing vid 1: 97/464.79s 0.040s   \n",
      "Processing vid 1: 98/464.67s 0.049s   \n",
      "Processing vid 1: 99/464.93s 0.040s   \n",
      "Processing vid 1: 100/464.0s 0.039s   \n",
      "Processing vid 1: 101/464.5s 0.043s   \n",
      "Processing vid 1: 102/464.4s 0.045s   \n",
      "Processing vid 1: 103/464.7s 0.049s   \n",
      "Processing vid 1: 104/464.1s 0.037s   \n",
      "Processing vid 1: 105/464.6s 0.037s   \n",
      "Processing vid 1: 106/464.8s 0.050s   \n",
      "Processing vid 1: 107/464.4s 0.052s   \n",
      "Processing vid 1: 108/464.1s 0.039s   \n",
      "Processing vid 1: 109/464.7s 0.040s   \n",
      "Processing vid 1: 110/464.0s 0.031s   \n",
      "Processing vid 1: 111/464.6s 0.037s   \n",
      "Processing vid 1: 112/464.3s 0.039s   \n",
      "Processing vid 1: 113/464.2s 0.038s   \n",
      "Processing vid 1: 114/464.4s 0.036s   \n",
      "Processing vid 1: 115/464.7s 0.037s   \n",
      "Processing vid 1: 116/464.7s 0.034s   \n",
      "Processing vid 1: 117/464.6s 0.036s   \n",
      "Processing vid 1: 118/464.6s 0.040s   \n",
      "Processing vid 1: 119/464.9s 0.034s   \n",
      "Processing vid 1: 120/464.8s 0.039s   \n",
      "Processing vid 1: 121/464.6s 0.036s   \n",
      "Processing vid 1: 122/464.8s 0.033s   \n",
      "Processing vid 1: 123/464.9s 0.039s   \n",
      "Processing vid 1: 124/464.9s 0.036s   \n",
      "Processing vid 1: 125/464.5s 0.042s   \n",
      "Processing vid 1: 126/464.4s 0.036s   \n",
      "Processing vid 1: 127/464.0s 0.034s   \n",
      "Processing vid 1: 128/464.5s 0.038s   \n",
      "Processing vid 1: 129/464.8s 0.032s   \n",
      "Processing vid 1: 130/464.1s 0.041s   \n",
      "Processing vid 1: 131/464.1s 0.035s   \n",
      "Processing vid 1: 132/464.5s 0.030s   \n",
      "Processing vid 1: 133/464.5s 0.040s   \n",
      "Processing vid 1: 134/464.4s 0.032s   \n",
      "Processing vid 1: 135/464.7s 0.044s   \n",
      "Processing vid 1: 136/464.2s 0.038s   \n",
      "Processing vid 1: 137/464.4s 0.038s   \n",
      "Processing vid 1: 138/464.5s 0.033s   \n",
      "Processing vid 1: 139/464.2s 0.033s   \n",
      "Processing vid 1: 140/464.3s 0.037s   \n",
      "Processing vid 1: 141/464.0s 0.032s   \n",
      "Processing vid 1: 142/464.6s 0.034s   \n",
      "Processing vid 1: 143/464.5s 0.037s   \n",
      "Processing vid 1: 144/464.7s 0.037s   \n",
      "Processing vid 1: 145/464.6s 0.035s   \n",
      "Processing vid 1: 146/464.2s 0.037s   \n",
      "Processing vid 1: 147/464.6s 0.035s   \n",
      "Processing vid 1: 148/464.4s 0.035s   \n",
      "Processing vid 1: 149/464.7s 0.042s   \n",
      "Processing vid 1: 150/464.6s 0.035s   \n",
      "Processing vid 1: 151/464.9s 0.036s   \n",
      "Processing vid 1: 152/464.0s 0.038s   \n",
      "Processing vid 1: 153/464.9s 0.038s   \n",
      "Processing vid 1: 154/464.2s 0.042s   \n",
      "Processing vid 1: 155/464.5s 0.042s   \n",
      "Processing vid 1: 156/464.7s 0.032s   \n",
      "Processing vid 1: 157/464.0s 0.038s   \n",
      "Processing vid 1: 158/464.6s 0.041s   \n",
      "Processing vid 1: 159/464.4s 0.039s   \n",
      "Processing vid 1: 160/464.6s 0.046s   \n",
      "Processing vid 1: 161/464.5s 0.040s   \n",
      "Processing vid 1: 162/464.1s 0.037s   \n",
      "Processing vid 1: 163/464.2s 0.034s   \n",
      "Processing vid 1: 164/464.2s 0.035s   \n",
      "Processing vid 1: 165/464.4s 0.036s   \n",
      "Processing vid 1: 166/464.8s 0.035s   \n",
      "Processing vid 1: 167/464.7s 0.040s   \n",
      "Processing vid 1: 168/464.7s 0.033s   \n",
      "Processing vid 1: 169/464.8s 0.038s   \n",
      "Processing vid 1: 170/464.7s 0.044s   \n",
      "Processing vid 1: 171/464.1s 0.036s   \n",
      "Processing vid 1: 172/464.3s 0.040s   \n",
      "Processing vid 1: 173/464.8s 0.038s   \n",
      "Processing vid 1: 174/464.0s 0.040s   \n",
      "Processing vid 1: 175/464.8s 0.038s   \n",
      "Processing vid 1: 176/464.8s 0.043s   \n",
      "Processing vid 1: 177/464.0s 0.045s   \n",
      "Processing vid 1: 178/464.7s 0.036s   \n",
      "Processing vid 1: 179/464.0s 0.036s   \n",
      "Processing vid 1: 180/464.3s 0.045s   \n",
      "Processing vid 1: 181/464.0s 0.037s   \n",
      "Processing vid 1: 182/464.6s 0.039s   \n",
      "Processing vid 1: 183/464.9s 0.038s   \n",
      "Processing vid 1: 184/464.4s 0.036s   \n",
      "Processing vid 1: 185/464.8s 0.033s   \n",
      "Processing vid 1: 186/464.3s 0.036s   \n",
      "Processing vid 1: 187/464.7s 0.037s   \n",
      "Processing vid 1: 188/464.4s 0.035s   \n",
      "Processing vid 1: 189/464.8s 0.036s   \n",
      "Processing vid 1: 190/464.6s 0.036s   \n",
      "Processing vid 1: 191/464.1s 0.035s   \n",
      "Processing vid 1: 192/464.3s 0.042s   \n",
      "Processing vid 1: 193/464.4s 0.040s   \n",
      "Processing vid 1: 194/464.5s 0.039s   \n",
      "Processing vid 1: 195/464.2s 0.041s   \n",
      "Processing vid 1: 196/464.5s 0.040s   \n",
      "Processing vid 1: 197/464.9s 0.038s   \n",
      "Processing vid 1: 198/464.0s 0.041s   \n",
      "Processing vid 1: 199/464.7s 0.039s   \n",
      "Processing vid 1: 200/464.9s 0.041s   \n",
      "Processing vid 1: 201/464.9s 0.038s   \n",
      "Processing vid 1: 202/464.7s 0.042s   \n",
      "Processing vid 1: 203/464.7s 0.039s   \n",
      "Processing vid 1: 204/464.4s 0.039s   \n",
      "Processing vid 1: 205/464.5s 0.042s   \n",
      "Processing vid 1: 206/464.9s 0.041s   \n",
      "Processing vid 1: 207/464.6s 0.033s   \n",
      "Processing vid 1: 208/464.7s 0.037s   \n",
      "Processing vid 1: 209/464.2s 0.036s   \n",
      "Processing vid 1: 210/464.5s 0.040s   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing vid 1: 211/464.1s 0.045s   \n",
      "Processing vid 1: 212/464.1s 0.040s   \n",
      "Processing vid 1: 213/464.1s 0.038s   \n",
      "Processing vid 1: 214/464.3s 0.038s   \n",
      "Processing vid 1: 215/464.9s 0.035s   \n",
      "Processing vid 1: 216/464.5s 0.036s   \n",
      "Processing vid 1: 217/464.4s 0.039s   \n",
      "Processing vid 1: 218/464.3s 0.043s   \n",
      "Processing vid 1: 219/464.4s 0.037s   \n",
      "Processing vid 1: 220/464.9s 0.037s   \n",
      "Processing vid 1: 221/464.6s 0.045s   \n",
      "Processing vid 1: 222/464.8s 0.035s   \n",
      "Processing vid 1: 223/464.3s 0.037s   \n",
      "Processing vid 1: 224/464.6s 0.036s   \n",
      "Processing vid 1: 225/464.7s 0.042s   \n",
      "Processing vid 1: 226/464.7s 0.046s   \n",
      "Processing vid 1: 227/464.8s 0.038s   \n",
      "Processing vid 1: 228/464.8s 0.042s   \n",
      "Processing vid 1: 229/464.3s 0.035s   \n",
      "Processing vid 1: 230/464.6s 0.034s   \n",
      "Processing vid 1: 231/464.8s 0.042s   \n",
      "Processing vid 1: 232/464.4s 0.043s   \n",
      "Processing vid 1: 233/464.5s 0.044s   \n",
      "Processing vid 1: 234/464.1s 0.037s   \n",
      "Processing vid 1: 235/464.2s 0.039s   \n",
      "Processing vid 1: 236/464.4s 0.039s   \n",
      "Processing vid 1: 237/464.5s 0.039s   \n",
      "Processing vid 1: 238/464.0s 0.040s   \n",
      "Processing vid 1: 239/464.3s 0.038s   \n",
      "Processing vid 1: 240/464.3s 0.037s   \n",
      "Processing vid 1: 241/464.4s 0.039s   \n",
      "Processing vid 1: 242/464.1s 0.035s   \n",
      "Processing vid 1: 243/464.3s 0.039s   \n",
      "Processing vid 1: 244/464.8s 0.036s   \n",
      "Processing vid 1: 245/464.1s 0.043s   \n",
      "Processing vid 1: 246/464.1s 0.056s   \n",
      "Processing vid 1: 247/464.2s 0.040s   \n",
      "Processing vid 1: 248/464.8s 0.044s   \n",
      "Processing vid 1: 249/464.4s 0.046s   \n",
      "Processing vid 1: 250/464.6s 0.045s   \n",
      "Processing vid 1: 251/464.6s 0.041s   \n",
      "Processing vid 1: 252/464.4s 0.041s   \n",
      "Processing vid 1: 253/464.4s 0.048s   \n",
      "Processing vid 1: 254/464.4s 0.044s   \n",
      "Processing vid 1: 255/464.2s 0.037s   \n",
      "Processing vid 1: 256/464.3s 0.044s   \n",
      "Processing vid 1: 257/464.7s 0.061s   \n",
      "Processing vid 1: 258/464.5s 0.040s   \n",
      "Processing vid 1: 259/464.2s 0.042s   \n",
      "Processing vid 1: 260/464.6s 0.038s   \n",
      "Processing vid 1: 261/464.3s 0.041s   \n",
      "Processing vid 1: 262/464.6s 0.041s   \n",
      "Processing vid 1: 263/464.2s 0.047s   \n",
      "Processing vid 1: 264/464.4s 0.053s   \n",
      "Processing vid 1: 265/464.8s 0.044s   \n",
      "Processing vid 1: 266/464.1s 0.048s   \n",
      "Processing vid 1: 267/464.7s 0.052s   \n",
      "Processing vid 1: 268/464.5s 0.059s   \n",
      "Processing vid 1: 269/464.5s 0.030s   \n",
      "Processing vid 1: 270/464.1s 0.035s   \n",
      "Processing vid 1: 271/464.9s 0.003s   \n",
      "Processing vid 1: 272/464.3s 0.005s   \n",
      "Processing vid 1: 273/464.6s 0.036s   \n",
      "Processing vid 1: 274/464.0s 0.016s   \n",
      "Processing vid 1: 275/464.6s 0.037s   \n",
      "Processing vid 1: 276/464.1s 0.010s   \n",
      "Processing vid 1: 277/464.0s 0.012s   \n",
      "Processing vid 1: 278/464.1s 0.026s   \n",
      "Processing vid 1: 279/464.2s 0.036s   \n",
      "Processing vid 1: 280/464.0s 0.037s   \n",
      "Processing vid 1: 281/464.3s 0.040s   \n",
      "Processing vid 1: 282/464.3s 0.036s   \n",
      "Processing vid 1: 283/464.2s 0.006s   \n",
      "Processing vid 1: 284/464.5s 0.017s   \n",
      "Processing vid 1: 285/464.0s 0.013s   \n",
      "Processing vid 1: 286/464.6s 0.005s   \n",
      "Processing vid 1: 287/464.8s 0.028s   \n",
      "Processing vid 1: 288/464.6s 0.011s   \n",
      "Processing vid 1: 289/464.2s 0.015s   \n",
      "Processing vid 1: 290/464.6s 0.008s   \n",
      "Processing vid 1: 291/464.3s 0.010s   \n",
      "Processing vid 1: 292/464.2s 0.013s   \n",
      "Processing vid 1: 293/464.0s 0.016s   \n",
      "Processing vid 1: 294/464.2s 0.012s   \n",
      "Processing vid 1: 295/464.5s 0.075s   \n",
      "Processing vid 1: 296/464.9s 0.029s   \n",
      "Processing vid 1: 297/464.9s 0.053s   \n",
      "Processing vid 1: 298/464.5s 0.049s   \n",
      "Processing vid 1: 299/464.1s 0.008s   \n",
      "Processing vid 1: 300/464.9s 0.014s   \n",
      "Processing vid 1: 301/464.1s 0.032s   \n",
      "Processing vid 1: 302/464.9s 0.006s   \n",
      "Processing vid 1: 303/464.3s 0.005s   \n",
      "Processing vid 1: 304/464.9s 0.013s   \n",
      "Processing vid 1: 305/464.5s 0.052s   \n",
      "Processing vid 1: 306/464.3s 0.025s   \n",
      "Processing vid 1: 307/464.3s 0.027s   \n",
      "Processing vid 1: 308/464.6s 0.051s   \n",
      "Processing vid 1: 309/464.8s 0.073s   \n",
      "Processing vid 1: 310/464.4s 0.020s   \n",
      "Processing vid 1: 311/464.3s 0.025s   \n",
      "Processing vid 1: 312/464.9s 0.032s   \n",
      "Processing vid 1: 313/464.3s 0.038s   \n",
      "Processing vid 1: 314/464.2s 0.037s   \n",
      "Processing vid 1: 315/464.7s 0.052s   \n",
      "Processing vid 1: 316/464.1s 0.072s   \n",
      "Processing vid 1: 317/464.8s 0.075s   \n",
      "Processing vid 1: 318/464.1s 0.075s   \n",
      "Processing vid 1: 319/464.1s 0.065s   \n",
      "Processing vid 1: 320/464.9s 0.056s   \n",
      "Processing vid 1: 321/464.4s 0.072s   \n",
      "Processing vid 1: 322/464.1s 0.053s   \n",
      "Processing vid 1: 323/464.8s 0.076s   \n",
      "Processing vid 1: 324/464.7s 0.063s   \n",
      "Processing vid 1: 325/464.0s 0.069s   \n",
      "Processing vid 1: 326/464.5s 0.061s   \n",
      "Processing vid 1: 327/464.6s 0.057s   \n",
      "Processing vid 1: 328/464.8s 0.060s   \n",
      "Processing vid 1: 329/464.4s 0.056s   \n",
      "Processing vid 1: 330/464.0s 0.053s   \n",
      "Processing vid 1: 331/464.4s 0.069s   \n",
      "Processing vid 1: 332/464.9s 0.057s   \n",
      "Processing vid 1: 333/464.1s 0.055s   \n",
      "Processing vid 1: 334/464.9s 0.048s   \n",
      "Processing vid 1: 335/464.3s 0.042s   \n",
      "Processing vid 1: 336/464.3s 0.039s   \n",
      "Processing vid 1: 337/464.5s 0.049s   \n",
      "Processing vid 1: 338/464.5s 0.047s   \n",
      "Processing vid 1: 339/464.4s 0.057s   \n",
      "Processing vid 1: 340/464.9s 0.054s   \n",
      "Processing vid 1: 341/464.8s 0.037s   \n",
      "Processing vid 1: 342/464.2s 0.042s   \n",
      "Processing vid 1: 343/464.0s 0.044s   \n",
      "Processing vid 1: 344/464.0s 0.051s   \n",
      "Processing vid 1: 345/464.5s 0.045s   \n",
      "Processing vid 1: 346/464.5s 0.038s   \n",
      "Processing vid 1: 347/464.1s 0.049s   \n",
      "Processing vid 1: 348/464.6s 0.041s   \n",
      "Processing vid 1: 349/464.7s 0.045s   \n",
      "Processing vid 1: 350/464.1s 0.036s   \n",
      "Processing vid 1: 351/464.3s 0.054s   \n",
      "Processing vid 1: 352/464.4s 0.045s   \n",
      "Processing vid 1: 353/464.8s 0.046s   \n",
      "Processing vid 1: 354/464.6s 0.037s   \n",
      "Processing vid 1: 355/464.5s 0.037s   \n",
      "Processing vid 1: 356/464.5s 0.038s   \n",
      "Processing vid 1: 357/464.1s 0.057s   \n",
      "Processing vid 1: 358/464.1s 0.058s   \n",
      "Processing vid 1: 359/464.3s 0.057s   \n",
      "Processing vid 1: 360/464.2s 0.067s   \n",
      "Processing vid 1: 361/464.0s 0.049s   \n",
      "Processing vid 1: 362/464.2s 0.042s   \n",
      "Processing vid 1: 363/464.0s 0.053s   \n",
      "Processing vid 1: 364/464.9s 0.059s   \n",
      "Processing vid 1: 365/464.5s 0.045s   \n",
      "Processing vid 1: 366/464.2s 0.044s   \n",
      "Processing vid 1: 367/464.9s 0.036s   \n",
      "Processing vid 1: 368/464.4s 0.042s   \n",
      "Processing vid 1: 369/464.5s 0.046s   \n",
      "Processing vid 1: 370/464.2s 0.050s   \n",
      "Processing vid 1: 371/464.3s 0.042s   \n",
      "Processing vid 1: 372/464.8s 0.043s   \n",
      "Processing vid 1: 373/464.4s 0.043s   \n",
      "Processing vid 1: 374/464.7s 0.057s   \n",
      "Processing vid 1: 375/464.0s 0.049s   \n",
      "Processing vid 1: 376/464.9s 0.057s   \n",
      "Processing vid 1: 377/464.5s 0.051s   \n",
      "Processing vid 1: 378/464.9s 0.039s   \n",
      "Processing vid 1: 379/464.3s 0.052s   \n",
      "Processing vid 1: 380/464.6s 0.048s   \n",
      "Processing vid 1: 381/464.8s 0.035s   \n",
      "Processing vid 1: 382/464.9s 0.039s   \n",
      "Processing vid 1: 383/464.2s 0.039s   \n",
      "Processing vid 1: 384/464.3s 0.045s   \n",
      "Processing vid 1: 385/464.5s 0.053s   \n",
      "Processing vid 1: 386/464.1s 0.050s   \n",
      "Processing vid 1: 387/464.5s 0.040s   \n",
      "Processing vid 1: 388/464.1s 0.039s   \n",
      "Processing vid 1: 389/464.8s 0.044s   \n",
      "Processing vid 1: 390/464.2s 0.047s   \n",
      "Processing vid 1: 391/464.1s 0.052s   \n",
      "Processing vid 1: 392/464.0s 0.051s   \n",
      "Processing vid 1: 393/464.8s 0.039s   \n",
      "Processing vid 1: 394/464.7s 0.049s   \n",
      "Processing vid 1: 395/464.8s 0.041s   \n",
      "Processing vid 1: 396/464.8s 0.041s   \n",
      "Processing vid 1: 397/464.8s 0.042s   \n",
      "Processing vid 1: 398/464.3s 0.037s   \n",
      "Processing vid 1: 399/464.3s 0.036s   \n",
      "Processing vid 1: 400/464.4s 0.035s   \n",
      "Processing vid 1: 401/464.0s 0.037s   \n",
      "Processing vid 1: 402/464.8s 0.055s   \n",
      "Processing vid 1: 403/464.4s 0.041s   \n",
      "Processing vid 1: 404/464.5s 0.050s   \n",
      "Processing vid 1: 405/464.1s 0.049s   \n",
      "Processing vid 1: 406/464.9s 0.048s   \n",
      "Processing vid 1: 407/464.8s 0.044s   \n",
      "Processing vid 1: 408/464.1s 0.047s   \n",
      "Processing vid 1: 409/464.5s 0.044s   \n",
      "Processing vid 1: 410/464.5s 0.047s   \n",
      "Processing vid 1: 411/464.6s 0.049s   \n",
      "Processing vid 1: 412/464.6s 0.037s   \n",
      "Processing vid 1: 413/464.2s 0.035s   \n",
      "Processing vid 1: 414/464.1s 0.045s   \n",
      "Processing vid 1: 415/464.9s 0.050s   \n",
      "Processing vid 1: 416/464.1s 0.044s   \n",
      "Processing vid 1: 417/464.9s 0.040s   \n",
      "Processing vid 1: 418/464.9s 0.044s   \n",
      "Processing vid 1: 419/464.4s 0.040s   \n",
      "Processing vid 1: 420/464.0s 0.047s   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing vid 1: 421/464.4s 0.039s   \n",
      "Processing vid 1: 422/464.7s 0.039s   \n",
      "Processing vid 1: 423/464.4s 0.039s   \n",
      "Processing vid 1: 424/464.2s 0.060s   \n",
      "Processing vid 1: 425/464.4s 0.043s   \n",
      "Processing vid 1: 426/464.0s 0.062s   \n",
      "Processing vid 1: 427/464.1s 0.059s   \n",
      "Processing vid 1: 428/464.0s 0.054s   \n",
      "Processing vid 1: 429/464.1s 0.067s   \n",
      "Processing vid 1: 430/464.5s 0.059s   \n",
      "Processing vid 1: 431/464.2s 0.045s   \n",
      "Processing vid 1: 432/464.6s 0.051s   \n",
      "Processing vid 1: 433/464.0s 0.055s   \n",
      "Processing vid 1: 434/464.3s 0.056s   \n",
      "Processing vid 1: 435/464.7s 0.039s   \n",
      "Processing vid 1: 436/464.7s 0.055s   \n",
      "Processing vid 1: 437/464.6s 0.058s   \n",
      "Processing vid 1: 438/464.6s 0.045s   \n",
      "Processing vid 1: 439/464.9s 0.039s   \n",
      "Processing vid 1: 440/464.0s 0.041s   \n",
      "Processing vid 1: 441/464.7s 0.040s   \n",
      "Processing vid 1: 442/464.8s 0.039s   \n",
      "Processing vid 1: 443/464.1s 0.035s   \n",
      "Processing vid 1: 444/464.7s 0.038s   \n",
      "Processing vid 1: 445/464.2s 0.040s   \n",
      "Processing vid 1: 446/464.4s 0.040s   \n",
      "Processing vid 1: 447/464.6s 0.046s   \n",
      "Processing vid 1: 448/464.5s 0.046s   \n",
      "Processing vid 1: 449/464.5s 0.045s   \n",
      "Processing vid 1: 450/464.6s 0.050s   \n",
      "Processing vid 1: 451/464.3s 0.055s   \n",
      "Processing vid 1: 452/464.0s 0.051s   \n",
      "Processing vid 1: 453/464.8s 0.048s   \n",
      "Processing vid 1: 454/464.8s 0.061s   \n",
      "Processing vid 1: 455/464.6s 0.052s   \n",
      "Processing vid 1: 456/464.2s 0.055s   \n",
      "Processing vid 1: 457/464.2s 0.045s   \n",
      "Processing vid 1: 458/464.4s 0.046s   \n",
      "Processing vid 1: 459/464.6s 0.049s   \n",
      "Processing vid 1: 460/464.5s 0.024s   \n",
      "Processing vid 1: 461/464.9s 0.052s   \n",
      "Processing vid 1: 462/464.1s 0.051s   \n",
      "Processing vid 1: 463/464.9s 0.039s   \n",
      "Processing vid 1: 464/464.7s 0.042s   \n",
      "test time: 152.6411s6 0.186s 0.038s   \n"
     ]
    }
   ],
   "source": [
    "#data_iter = iter(dataloader)\n",
    "\n",
    "_t = {'im_detect': time.time(), 'misc': time.time()}\n",
    "det_file = os.path.join(output_dir, 'detections.pkl')\n",
    "\n",
    "RCNN.eval()\n",
    "empty_array = np.transpose(np.array([[],[],[],[],[]]), (1,0))\n",
    "\n",
    "template_weights = None\n",
    "rois_tracking = None\n",
    "\n",
    "\n",
    "#for i in range(num_images):\n",
    "for i in range(imdb._structured_indexes[SEE_VID_ID][0],imdb._structured_indexes[SEE_VID_ID][-1]+1):\n",
    "    data = dataset.__getitem__(i)\n",
    "    print('Processing vid %d: %d/%d.' % (SEE_VID_ID, i-imdb._structured_indexes[SEE_VID_ID][0]+1,\n",
    "                                         len(imdb._structured_indexes[SEE_VID_ID])))\n",
    "    data = list(data)\n",
    "    data[0] = data[0].unsqueeze(0)\n",
    "    data[1] = data[1].unsqueeze(0)\n",
    "    data = tuple(data)\n",
    "    #data[2] = data[2].unsqueeze(0)\n",
    "    im_data.data.resize_(data[0].size()).copy_(data[0])\n",
    "    im_info.data.resize_(data[1].size()).copy_(data[1])\n",
    "    #gt_boxes.data.resize_(data[2].size()).copy_(data[2])\n",
    "    #num_boxes.data.resize_(data[3].size()).copy_(data[3])\n",
    "\n",
    "    input = im_data, im_info, template_weights, rois_tracking\n",
    "\n",
    "    det_tic = time.time()\n",
    "    siam_rois, siam_bbox_pred, siam_cls_prob, rois, rois_label, cls_prob, bbox_pred = RCNN(input)\n",
    "\n",
    "    ###########################################\n",
    "    # Get detection boxes.\n",
    "    ###########################################\n",
    "    if cfg.TEST.BBOX_REG:\n",
    "        scores = cls_prob.data\n",
    "        boxes = rois.data[:, :, 1:5]\n",
    "        pred_boxes = bbox_delta_to_pred_boxes(im_info, boxes, bbox_pred)\n",
    "        pred_boxes /= data[1][0][2].item()\n",
    "        scores = scores.squeeze()\n",
    "        pred_boxes = pred_boxes.squeeze()\n",
    "        if siam_bbox_pred is not None:\n",
    "            siam_scores = siam_cls_prob.data\n",
    "            siam_boxes = siam_rois.data[:, 1:5]\n",
    "            pred_siam_bbox = bbox_delta_to_pred_boxes(im_info, siam_boxes.unsqueeze(0), siam_bbox_pred.unsqueeze(0))\n",
    "            pred_siam_bbox /= data[1][0][2].item()\n",
    "            pred_siam_bbox = pred_siam_bbox.squeeze(0)\n",
    "            # concatenate siambox and detbox.\n",
    "            if MODE==0:\n",
    "                pred_boxes = torch.cat((pred_boxes, pred_siam_bbox), 0)\n",
    "                scores = torch.cat((scores, siam_scores), 0)\n",
    "            #####################\n",
    "            if MODE==2:\n",
    "                #####################\n",
    "                #pred_boxes = pred_siam_bbox\n",
    "                #####################\n",
    "                pred_boxes = siam_boxes.repeat(1,siam_boxes.size(1)*31)\n",
    "                pred_boxes = pred_boxes/im_info[0][-1]\n",
    "                scores = siam_scores\n",
    "    else:\n",
    "        raise ValueError('Error. Should set cfg.TEST.BBOX_REG to True.')\n",
    "\n",
    "    det_toc = time.time()\n",
    "    detect_time = det_toc - det_tic\n",
    "    misc_tic = time.time()\n",
    "    ###########################################\n",
    "    # NMS for detection and save to all boxes.\n",
    "    ###########################################\n",
    "    for j in xrange(1, imdb.num_classes):\n",
    "        inds = torch.nonzero(scores[:,j]>thresh).view(-1)\n",
    "        # if there is det\n",
    "        if inds.numel() > 0:\n",
    "            cls_scores = scores[:,j][inds]\n",
    "            all_scores = scores[inds]\n",
    "            _, order = torch.sort(cls_scores, 0, True)\n",
    "            if args.class_agnostic:\n",
    "                cls_boxes = pred_boxes[inds, :]\n",
    "            else:\n",
    "                cls_boxes = pred_boxes[inds][:, j * 4:(j + 1) * 4]\n",
    "\n",
    "            cls_dets = torch.cat((cls_boxes, cls_scores.unsqueeze(1)), 1)\n",
    "            # cls_dets = torch.cat((cls_boxes, cls_scores), 1)\n",
    "            cls_dets = cls_dets[order]\n",
    "            all_scores = all_scores[order]\n",
    "            ######### nms for each cls here ########\n",
    "            keep = nms(cls_dets, cfg.TEST.NMS)\n",
    "            cls_dets = cls_dets[keep.view(-1).long()]\n",
    "            all_cls_scores = all_scores[keep.view(-1).long()]\n",
    "            all_boxes[j][i] = cls_dets.cpu().numpy()\n",
    "            all_boxes_scores[j][i] = all_cls_scores.cpu().numpy()\n",
    "        else:\n",
    "            all_boxes[j][i] = empty_array\n",
    "            all_boxes_scores[j][i] = empty_array\n",
    "\n",
    "    # Limit to max_per_image detections *over all classes*\n",
    "    if max_per_image > 0:\n",
    "        image_scores = np.hstack([all_boxes[j][i][:, -1]\n",
    "                                for j in xrange(1, imdb.num_classes)])\n",
    "        if len(image_scores) > max_per_image:\n",
    "            image_thresh = np.sort(image_scores)[-max_per_image]\n",
    "            for j in xrange(1, imdb.num_classes):\n",
    "                keep = np.where(all_boxes[j][i][:, -1] >= image_thresh)[0]\n",
    "                all_boxes[j][i] = all_boxes[j][i][keep, :]\n",
    "                all_boxes_scores[j][i] = all_boxes_scores[j][i][keep, :]\n",
    "    ########\n",
    "    # Get weights for the next iteration.\n",
    "    ########\n",
    "    # First, convert all_boxes to rois_tracking.#\n",
    "    # TODO change threshold.\n",
    "    rois_tracking = prepare_rois_tracking(im_info[0], all_boxes, all_boxes_scores, frame_id=i,\n",
    "                                        class_num=imdb.num_classes, thresh=0.5)\n",
    "    base_feat = RCNN.track_feat_trans_1.cuda()(RCNN.RCNN.Conv_feat_track)\n",
    "    template_weights, rois_tracking = siam_weights_preparation(rois_tracking, base_feat)\n",
    "\n",
    "    misc_toc = time.time()\n",
    "    nms_time = misc_toc - misc_tic\n",
    "\n",
    "    sys.stdout.write('im_detect: {:d}/{:d} {:.3f}s {:.3f}s   \\r' \\\n",
    "      .format(i + 1, num_images, detect_time, nms_time))\n",
    "    sys.stdout.flush()\n",
    "\n",
    "#with open(det_file, 'wb') as f:\n",
    "    #pickle.dump(all_boxes, f, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "#print('Evaluating detections')\n",
    "#imdb.evaluate_detections(all_boxes, output_dir)\n",
    "\n",
    "end = time.time()\n",
    "print(\"test time: %0.4fs\" % (end - start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Examine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "464 927\n"
     ]
    }
   ],
   "source": [
    "print(imdb._structured_indexes[SEE_VID_ID][0],imdb._structured_indexes[SEE_VID_ID][-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io as sio\n",
    "devkit_path = 'data/imagenet/ILSVRC/devkit'\n",
    "####VID object info####\n",
    "synsets_video = sio.loadmat(os.path.join(devkit_path,'data','meta_vid.mat'))\n",
    "_wnid = (0,)\n",
    "_classes = ('__background__',)\n",
    "for i in xrange(30):\n",
    "    _classes = _classes + (synsets_video['synsets'][0][i][2][0],)\n",
    "    _wnid = _wnid + (synsets_video['synsets'][0][i][1][0],)\n",
    "\n",
    "_wnid_to_ind = dict(zip(_wnid, xrange(31)))\n",
    "_class_to_ind = dict(zip(_classes, xrange(31)))\n",
    "#######################\n",
    "def read_annotation(dataPath):\n",
    "    filename = dataPath.replace('Data','Annotations').replace('JPEG','xml')\n",
    "    assert os.path.exists(filename),'%s'%(filename)\n",
    "    # print 'Loading: {}'.format(filename)\n",
    "    def get_data_from_tag(node, tag):\n",
    "        return node.getElementsByTagName(tag)[0].childNodes[0].data\n",
    "\n",
    "    with open(filename) as f:\n",
    "        data = minidom.parseString(f.read())\n",
    "\n",
    "    objs = data.getElementsByTagName('object')\n",
    "    num_objs = len(objs)\n",
    "    \n",
    "    boxes = np.zeros((num_objs, 4), dtype=np.int32)\n",
    "    gt_classes = np.zeros(num_objs,dtype=np.int32)\n",
    "    # Load object bounding boxes into a data frame.\n",
    "    for ix, obj in enumerate(objs):\n",
    "        x1 = float(get_data_from_tag(obj, 'xmin'))\n",
    "        y1 = float(get_data_from_tag(obj, 'ymin'))\n",
    "        x2 = float(get_data_from_tag(obj, 'xmax'))\n",
    "        y2 = float(get_data_from_tag(obj, 'ymax'))\n",
    "        cls = _wnid_to_ind[\n",
    "                str(get_data_from_tag(obj, \"name\")).lower().strip()]\n",
    "        boxes[ix, :] = [x1, y1, x2, y2]\n",
    "        gt_classes[ix] = cls\n",
    "    return boxes, gt_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "def showBoxResult(img_id, all_boxes, imdb, show_class=True, threshold=0.3, dpi = 200):\n",
    "    imIdx = imdb.image_index[img_id]+'.JPEG'\n",
    "    assert os.path.exists(imIdx), imIdx+' does not exist.'\n",
    "    #print(imIdx)\n",
    "    gt_boxes, gt_classes = read_annotation(imIdx)\n",
    "    im2show = np.array(PIL.Image.open(imIdx))\n",
    "    fig = plt.figure(frameon=False)\n",
    "    fig.set_size_inches(im2show.shape[1] / dpi, im2show.shape[0] / dpi)\n",
    "    ax = plt.Axes(fig, [0., 0., 1., 1.])\n",
    "    ax.axis('off')\n",
    "    fig.add_axes(ax)\n",
    "    ax.imshow(im2show)\n",
    "    \n",
    "    #draw gt first\n",
    "    for j in range(len(gt_classes)):\n",
    "        ax.add_patch(\n",
    "        plt.Rectangle((gt_boxes[j][0], gt_boxes[j][1]),\n",
    "                      gt_boxes[j][2] - gt_boxes[j][0],\n",
    "                      gt_boxes[j][3] - gt_boxes[j][1],\n",
    "                      fill=False, edgecolor='g',\n",
    "                      linewidth=3.0, alpha=0.8))\n",
    "        if show_class:\n",
    "            ax.text(gt_boxes[j][0], gt_boxes[j][1] - 2,\n",
    "            '%s %f'%(imdb.classes[gt_classes[j]], 1.0),\n",
    "            fontsize=10,\n",
    "            #family='serif',\n",
    "            bbox=dict(facecolor='g', alpha=0.5, pad=0, edgecolor='none'),\n",
    "                color='white')\n",
    "    \n",
    "    #draw dets\n",
    "    for j in range(len(imdb.classes)):\n",
    "        if isinstance(all_boxes[j][img_id], np.ndarray):\n",
    "            for bbox in all_boxes[j][img_id]:\n",
    "                if bbox[-1]>threshold:\n",
    "                    ax.add_patch(\n",
    "                    plt.Rectangle((bbox[0], bbox[1]),\n",
    "                              bbox[2] - bbox[0],\n",
    "                              bbox[3] - bbox[1],\n",
    "                              fill=False, edgecolor='y',\n",
    "                              linewidth=3.0, alpha=0.4))\n",
    "                    if show_class:\n",
    "                        ax.text(bbox[0], bbox[1] - 2,\n",
    "                        '%s %f'%(imdb.classes[j], bbox[-1]),\n",
    "                        fontsize=10,\n",
    "                        #family='serif',\n",
    "                        bbox=dict(\n",
    "                            facecolor='y', alpha=0.5, pad=0, edgecolor='none'),\n",
    "                            color='white')\n",
    "            #im2show = vis_detections(im2show, imdb.classes[j], all_boxes[j][img_id], 0.3)\n",
    "    #plt.show()\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "def makeVid(imdb,all_boxes,img_ids,vid_id,dname_prefix='tmp_vid',dir_suffix='',ext='png'):\n",
    "    name_ls = []\n",
    "    dname = dname_prefix+'_%03d'%(vid_id)+dir_suffix\n",
    "    if not os.path.exists(dname):\n",
    "        os.mkdir(dname)\n",
    "        assert os.path.exists(dname)\n",
    "    for i in img_ids:\n",
    "        fname = os.path.join(dname,'%08d'%(i)+'.'+ext)\n",
    "        fig = showBoxResult(i,all_boxes,imdb)\n",
    "        fig.savefig(fname)\n",
    "        plt.close(fig)\n",
    "        name_ls.append(fname)\n",
    "    return name_ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_ids = imdb._structured_indexes[SEE_VID_ID]\n",
    "dir_suffix = ''\n",
    "if MODE==1:\n",
    "    dir_suffix='_det'\n",
    "elif MODE==2:\n",
    "    dir_suffix='_tra'\n",
    "name_ls = makeVid(imdb,all_boxes,img_ids,SEE_VID_ID,dname_prefix='tmp_vid',dir_suffix=dir_suffix,ext='pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge all images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PyPDF2 import PdfFileMerger\n",
    "\n",
    "pdfs = name_ls\n",
    "merger = PdfFileMerger()\n",
    "\n",
    "for pdf in pdfs:\n",
    "    merger.append(open(pdf, 'rb'))\n",
    "\n",
    "with open(os.path.join(os.path.dirname(pdfs[0]),'result.pdf'), 'wb') as fout:\n",
    "    merger.write(fout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
